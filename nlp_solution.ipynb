{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science / Machine Learning Meetup #1 Deep Learning Hands-on\n",
    "# オルタナティブ・データと自然言語処理\n",
    "\n",
    "## はじめに\n",
    "\n",
    "演習の概略は以下の通りです。\n",
    "1. [環境準備](#環境準備)\n",
    "1. [WEBスクレイピング](#WEBスクレイピング)\n",
    "1. [感情分析](#感情分析)\n",
    "    1. 前処理\n",
    "    1. ニューラル・ネットワーク構築\n",
    "    1. トレーニング\n",
    "    1. 予測\n",
    "\n",
    "以下の点にご注意ください。\n",
    "- 実行するコードの中に、ご利用中のユーザー名に合わせて、変更していただく部分があります。\n",
    "\n",
    "## 環境準備\n",
    "\n",
    "### パッケージのインストールとインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipython-sql==0.3.9\n",
      "  Downloading https://files.pythonhosted.org/packages/ab/df/427e7cf05ffc67e78672ad57dce2436c1e825129033effe6fcaf804d0c60/ipython_sql-0.3.9-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from ipython-sql==0.3.9) (1.12.0)\n",
      "Requirement already satisfied: ipython>=1.0 in /usr/local/lib/python3.6/dist-packages (from ipython-sql==0.3.9) (5.1.0)\n",
      "Requirement already satisfied: ipython-genutils>=0.1.0 in /usr/local/lib/python3.6/dist-packages (from ipython-sql==0.3.9) (0.2.0)\n",
      "Collecting prettytable (from ipython-sql==0.3.9)\n",
      "  Downloading https://files.pythonhosted.org/packages/ef/30/4b0746848746ed5941f052479e7c23d2b56d174b82f4fd34a25e389831f5/prettytable-0.7.2.tar.bz2\n",
      "Collecting sqlalchemy>=0.6.7 (from ipython-sql==0.3.9)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/47/35edeb0f86c0b44934c05d961c893e223ef27e79e1f53b5e6f14820ff553/SQLAlchemy-1.3.13.tar.gz (6.0MB)\n",
      "\u001b[K     |████████████████████████████████| 6.0MB 9.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sqlparse (from ipython-sql==0.3.9)\n",
      "  Downloading https://files.pythonhosted.org/packages/ef/53/900f7d2a54557c6a37886585a91336520e5539e3ae2423ff1102daf4f3a7/sqlparse-0.3.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=1.0->ipython-sql==0.3.9) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.3 in /usr/local/lib/python3.6/dist-packages (from ipython>=1.0->ipython-sql==0.3.9) (1.0.15)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=1.0->ipython-sql==0.3.9) (41.0.1)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=1.0->ipython-sql==0.3.9) (2.4.2)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython>=1.0->ipython-sql==0.3.9) (4.3.2)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=1.0->ipython-sql==0.3.9) (4.7.0)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=1.0->ipython-sql==0.3.9) (0.8.1)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython>=1.0->ipython-sql==0.3.9) (4.4.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.3->ipython>=1.0->ipython-sql==0.3.9) (0.1.7)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=1.0->ipython-sql==0.3.9) (0.6.0)\n",
      "Building wheels for collected packages: prettytable, sqlalchemy\n",
      "  Building wheel for prettytable (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/cdsw/.cache/pip/wheels/80/34/1c/3967380d9676d162cb59513bd9dc862d0584e045a162095606\n",
      "  Building wheel for sqlalchemy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/cdsw/.cache/pip/wheels/b3/35/98/4c9cb3fd63d21d5606b972dd70643769745adf60e622467b71\n",
      "Successfully built prettytable sqlalchemy\n",
      "Installing collected packages: prettytable, sqlalchemy, sqlparse, ipython-sql\n",
      "Successfully installed ipython-sql-0.3.9 prettytable-0.7.2 sqlalchemy-1.3.13 sqlparse-0.3.0\n",
      "\u001b[33mWARNING: You are using pip version 19.1.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting PyHive==0.6.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/26/de91125c0d9e8947d48f387f4d1f2e7a22aa92a30771ad02f63a5653361b/PyHive-0.6.1.tar.gz (41kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 2.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting future (from PyHive==0.6.1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
      "\u001b[K     |████████████████████████████████| 829kB 5.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from PyHive==0.6.1) (2.8.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil->PyHive==0.6.1) (1.12.0)\n",
      "Building wheels for collected packages: PyHive, future\n",
      "  Building wheel for PyHive (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/cdsw/.cache/pip/wheels/00/61/fb/77a0e77deb4c900276f689e62628a5ca7ba9df600f9ad7ba6a\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/cdsw/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
      "Successfully built PyHive future\n",
      "Installing collected packages: future, PyHive\n",
      "Successfully installed PyHive-0.6.1 future-0.18.2\n",
      "\u001b[33mWARNING: You are using pip version 19.1.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: SQLAlchemy==1.3.13 in ./.local/lib/python3.6/site-packages (1.3.13)\n",
      "\u001b[33mWARNING: You are using pip version 19.1.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting thrift==0.13.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/1e/3284d19d7be99305eda145b8aa46b0c33244e4a496ec66440dac19f8274d/thrift-0.13.0.tar.gz (59kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 2.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.7.2 in /usr/local/lib/python3.6/dist-packages (from thrift==0.13.0) (1.12.0)\n",
      "Building wheels for collected packages: thrift\n",
      "  Building wheel for thrift (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/cdsw/.cache/pip/wheels/02/a2/46/689ccfcf40155c23edc7cdbd9de488611c8fdf49ff34b1706e\n",
      "Successfully built thrift\n",
      "Installing collected packages: thrift\n",
      "Successfully installed thrift-0.13.0\n",
      "\u001b[33mWARNING: You are using pip version 19.1.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting sasl==0.2.1\n",
      "  Downloading https://files.pythonhosted.org/packages/8e/2c/45dae93d666aea8492678499e0999269b4e55f1829b1e4de5b8204706ad9/sasl-0.2.1.tar.gz\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sasl==0.2.1) (1.12.0)\n",
      "Building wheels for collected packages: sasl\n",
      "  Building wheel for sasl (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/cdsw/.cache/pip/wheels/56/20/21/ff481fd0f4ae09d5d94c76d089f550204580b1703e44f27dd5\n",
      "Successfully built sasl\n",
      "Installing collected packages: sasl\n",
      "Successfully installed sasl-0.2.1\n",
      "\u001b[33mWARNING: You are using pip version 19.1.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting thrift_sasl==0.3.0\n",
      "  Downloading https://files.pythonhosted.org/packages/50/fe/89cbc910809e3757c762f56ee190ca39e0f28b7ea451835232c0c988d706/thrift_sasl-0.3.0.tar.gz\n",
      "Requirement already satisfied: thrift>=0.10.0 in ./.local/lib/python3.6/site-packages (from thrift_sasl==0.3.0) (0.13.0)\n",
      "Requirement already satisfied: sasl>=0.2.1 in ./.local/lib/python3.6/site-packages (from thrift_sasl==0.3.0) (0.2.1)\n",
      "Requirement already satisfied: six>=1.7.2 in /usr/local/lib/python3.6/dist-packages (from thrift>=0.10.0->thrift_sasl==0.3.0) (1.12.0)\n",
      "Building wheels for collected packages: thrift-sasl\n",
      "  Building wheel for thrift-sasl (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/cdsw/.cache/pip/wheels/c8/3a/34/1d82df3d652788fc211c245d51dde857a58e603695ea41d93d\n",
      "Successfully built thrift-sasl\n",
      "Installing collected packages: thrift-sasl\n",
      "Successfully installed thrift-sasl-0.3.0\n",
      "\u001b[33mWARNING: You are using pip version 19.1.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting nltk==3.4.5\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5MB 4.0MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk==3.4.5) (1.12.0)\n",
      "Building wheels for collected packages: nltk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for nltk (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/cdsw/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n",
      "Successfully built nltk\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.4.5\n",
      "\u001b[33mWARNING: You are using pip version 19.1.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting torch==1.4.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/19/4804aea17cd136f1705a5e98a00618cb8f6ccc375ad8bfa437408e09d058/torch-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (753.4MB)\n",
      "\u001b[K     |████████████████████████████████| 753.4MB 41kB/s s eta 0:00:01     |█▌                              | 35.2MB 5.4MB/s eta 0:02:13[K     |█▊                              | 39.4MB 5.4MB/s eta 0:02:12     |██                              | 47.3MB 5.4MB/s eta 0:02:11MB/s eta 0:00:097MB 69.9MB/s eta 0:00:09| 191.8MB 69.9MB/s eta 0:00:091MB 56.1MB/s eta 0:00:10  | 276.2MB 72.9MB/s eta 0:00:07MB/s eta 0:00:05███████████████▋          | 508.0MB 69.2MB/s eta 0:00:04:00:03��        | 545.9MB 71.9MB/s eta 0:00:03█████████████▊        | 559.8MB 71.9MB/s eta 0:00:03MB/s eta 0:00:02MB/s eta 0:00:02��██████████████▍   | 669.5MB 69.7MB/s eta 0:00:02ta 0:00:01ta 0:00:01�███| 751.5MB 69.5MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: torch\n",
      "Successfully installed torch-1.4.0\n",
      "\u001b[33mWARNING: You are using pip version 19.1.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install ipython-sql==0.3.9\n",
    "!pip3 install PyHive==0.6.1\n",
    "!pip3 install SQLAlchemy==1.3.13\n",
    "!pip3 install thrift==0.13.0\n",
    "!pip3 install sasl==0.2.1\n",
    "!pip3 install thrift_sasl==0.3.0\n",
    "\n",
    "\n",
    "!pip3 install nltk==3.4.5\n",
    "!pip3 install torch==1.4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記でインストールしたPyHiveは、Pythonコードの中でimportして使われるのではなく、Hiveへの接続の際の接続文字列：`sqlalchemy.create_engine('hive://<host>:<port>')`の中でdialectsとして指定された際に必要になります。そのため、インストール後に利用するためには、新しくプロセスを始める必要があります。**インストールした後に一度、KernelをRestartしてください。**インストールしたプロセスでは、接続時に下記のようなエラーが発生します。\n",
    "`NoSuchModuleError: Can't load plugin: sqlalchemy.dialects:hive`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import subprocess\n",
    "import glob\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "\n",
    "from pyhive import hive\n",
    "import sqlalchemy\n",
    "\n",
    "import sys\n",
    "#from random import random\n",
    "from operator import add\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import torch\n",
    "import nltk\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WEBスクレイピング\n",
    "\n",
    "無償で利用できるAPIを用いて演習を行います。そのため、利用に一定の制限が課せられることにご留意ください。\n",
    "例えば、ご利用状況に応じて、下記のようなエラーメッセージを受け取ることがあります。\n",
    "\n",
    "```\n",
    "{\"response\":{\"status\":429},\"errors\":[{\"message\":\"Rate limit exceeded. Client may not make more than 200 requests an hour.\"}]}\n",
    "```\n",
    "まず、APIで取得したデータをCDSWプロジェクト内のファイルとして保存します。\n",
    "\n",
    "取得する銘柄の候補が、`ticker.txt`に定義されています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2882\n",
      "['A', 'AA', 'AAL', 'AAN', 'AAOI', 'AAON', 'AAP', 'AAPL', 'AAWW', 'AAXN', 'ABBV', 'ABC', 'ABCB', 'ABEO', 'ABG', 'ABM', 'ABMD', 'ABT', 'ABTX', 'ACA', 'ACAD', 'ACCO', 'ACEL', 'ACGL', 'ACHC', 'ACHN', 'ACHV', 'ACIA', 'ACIW', 'ACLS', 'ACM', 'ACN', 'ACNB', 'ACOR', 'ACRS', 'ACRX', 'ACTG', 'ADBE', 'ADES', 'ADI', 'ADM', 'ADMA', 'ADMP', 'ADMS', 'ADP', 'ADPT', 'ADRO', 'ADS', 'ADSK', 'ADSW', 'ADT', 'ADTN', 'ADUS', 'ADVM', 'ADXS', 'AE', 'AEE', 'AEGN', 'AEIS', 'AEL', 'AEM', 'AEMD', 'AEO', 'AEP', 'AERI', 'AES', 'AFG', 'AFI', 'AFL', 'AG', 'AGCO', 'AGEN', 'AGFS', 'AGI', 'AGIO', 'AGLE', 'AGM', 'AGN', 'AGO', 'AGR', 'AGRX', 'AGS', 'AGTC', 'AGX', 'AGYS', 'AHC', 'AHCO', 'AIG', 'AIMC', 'AIMT', 'AIN', 'AIR', 'AIRG', 'AIRT', 'AIT', 'AIZ', 'AJG', 'AJRD', 'AKAM', 'AKBA', 'AKCA', 'AKRO', 'AKRX', 'AKS', 'AL', 'ALB', 'ALCO', 'ALDX', 'ALE', 'ALEC', 'ALG', 'ALGN', 'ALGT', 'ALIM', 'ALK', 'ALKS', 'ALL', 'ALLK', 'ALLO', 'ALLY', 'ALNY', 'ALOT', 'ALPN', 'ALRM', 'ALRN', 'ALSK', 'ALSN', 'ALT', 'ALTR', 'ALV', 'ALXN', 'AM', 'AMAG', 'AMAL', 'AMAT', 'AMBA', 'AMBC', 'AMC', 'AMCX', 'AMD', 'AME', 'AMED', 'AMEH', 'AMG', 'AMGN', 'AMK', 'AMKR', 'AMN', 'AMNB', 'AMOT', 'AMP', 'AMPE', 'AMPH', 'AMRC', 'AMRS', 'AMRX', 'AMSC', 'AMSF', 'AMSWA', 'AMTB', 'AMTD', 'AMTX', 'AMWD', 'AMZN', 'AN', 'ANAB', 'ANAT', 'ANDA', 'ANDE', 'ANET', 'ANF', 'ANGI', 'ANGO', 'ANIK', 'ANIP', 'ANIX', 'ANSS', 'ANTM', 'AOBC', 'AON', 'AOS', 'AP', 'APA', 'APD', 'APDN', 'APEI', 'APEN', 'APH', 'APLS', 'APLT', 'APOG', 'APPF', 'APPN', 'APPS', 'APRE', 'APRN', 'APT', 'APTV', 'APY', 'AQB', 'AQN', 'AQUA', 'AR', 'ARA', 'ARAV', 'ARAY', 'ARCB', 'ARCH', 'ARCO', 'ARCT', 'ARDS', 'ARDX', 'ARES', 'ARGO', 'ARKR', 'ARLO', 'ARMK', 'ARMP', 'ARNA', 'ARNC', 'AROC', 'AROW', 'ARTNA', 'ARVN', 'ARW', 'ARWR', 'ASB', 'ASFI', 'ASGN', 'ASH', 'ASIX', 'ASMB', 'ASNA', 'ASPS', 'ASPU', 'ASRT', 'ASTE', 'ASYS', 'ATEC', 'ATEN', 'ATEX', 'ATGE', 'ATH', 'ATHX', 'ATI', 'ATKR', 'ATLO', 'ATNI', 'ATNX', 'ATO', 'ATR', 'ATRA', 'ATRC', 'ATRI', 'ATRO', 'ATRS', 'ATSG', 'ATUS', 'ATVI', 'AUB', 'AUMN', 'AUPH', 'AUTO', 'AUY', 'AVA', 'AVAV', 'AVD', 'AVGO', 'AVID', 'AVLR', 'AVNS', 'AVNW', 'AVRO', 'AVT', 'AVTR', 'AVX', 'AVXL', 'AVY', 'AVYA', 'AWI', 'AWK', 'AWR', 'AWRE', 'AX', 'AXAS', 'AXDX', 'AXGN', 'AXGT', 'AXL', 'AXLA', 'AXNX', 'AXP', 'AXS', 'AXSM', 'AXTA', 'AXTI', 'AYI', 'AYX', 'AZO', 'AZPN', 'AZZ', 'B', 'BA', 'BAC', 'BAH', 'BAM', 'BANC', 'BAND', 'BANF', 'BANR', 'BAP', 'BAX', 'BB', 'BBBY', 'BBI', 'BBIO', 'BBQ', 'BBW', 'BBY', 'BC', 'BCBP', 'BCC', 'BCE', 'BCEI', 'BCEL', 'BCLI', 'BCO', 'BCOR', 'BCOV', 'BCPC', 'BCRX', 'BDC', 'BDGE', 'BDSI', 'BDX', 'BE', 'BEAT', 'BECN', 'BELFB', 'BEN', 'BERY', 'BFAM', 'BFC', 'BFIN', 'BG', 'BGCP', 'BGFV', 'BGG', 'BGS', 'BH', 'BHB', 'BHC', 'BHE', 'BHF', 'BHLB', 'BIG', 'BIIB', 'BIMI', 'BIO', 'BIOS', 'BJ', 'BJRI', 'BK', 'BKD', 'BKE', 'BKH', 'BKI', 'BKNG', 'BKR', 'BKU', 'BL', 'BLBD', 'BLCM', 'BLD', 'BLDP', 'BLDR', 'BLFS', 'BLK', 'BLKB', 'BLL', 'BLMN', 'BLNK', 'BLUE', 'BLX', 'BMCH', 'BMI', 'BMO', 'BMRC', 'BMRN', 'BMTC', 'BMY', 'BNED', 'BNFT', 'BNGO', 'BNS', 'BOH', 'BOKF', 'BOMN', 'BOOM', 'BOOT', 'BOX', 'BPFH', 'BPMC', 'BPTH', 'BR', 'BRC', 'BRKB', 'BRKL', 'BRKR', 'BRKS', 'BRMK', 'BRO', 'BRY', 'BSET', 'BSIG', 'BSQR', 'BSRR', 'BSTC', 'BSX', 'BTG', 'BURL', 'BUSE', 'BV', 'BWA', 'BWEN', 'BWXT', 'BX', 'BXC', 'BXG', 'BXS', 'BY', 'BYD', 'BYND', 'BZH', 'C', 'CABO', 'CAC', 'CACC', 'CACI', 'CADE', 'CAG', 'CAH', 'CAI', 'CAKE', 'CAL', 'CALA', 'CALM', 'CALX', 'CAMP', 'CAPR', 'CAR', 'CARA', 'CARE', 'CARG', 'CARS', 'CASA', 'CASH', 'CASI', 'CASS', 'CASY', 'CAT', 'CATB', 'CATM', 'CATO', 'CATY', 'CBIO', 'CBMG', 'CBPO', 'CBPX', 'CBRE', 'CBRL', 'CBSH', 'CBT', 'CBTX', 'CBU', 'CBZ', 'CC', 'CCBG', 'CCEP', 'CCF', 'CCJ', 'CCK', 'CCL', 'CCMP', 'CCNE', 'CCO', 'CCOI', 'CCRN', 'CCS', 'CCXI', 'CDAY', 'CDE', 'CDK', 'CDLX', 'CDMO', 'CDNA', 'CDNS', 'CDW', 'CDXS', 'CE', 'CECE', 'CEIX', 'CEL', 'CELH', 'CEMI', 'CENT', 'CENTA', 'CENX', 'CERN', 'CERS', 'CEVA', 'CF', 'CFB', 'CFFI', 'CFFN', 'CFG', 'CFMS', 'CFR', 'CFX', 'CGC', 'CGEN', 'CGNX', 'CHCO', 'CHD', 'CHDN', 'CHE', 'CHEF', 'CHGG', 'CHH', 'CHK', 'CHKP', 'CHMA', 'CHMG', 'CHNG', 'CHRS', 'CHRW', 'CHS', 'CHTR', 'CHUY', 'CHWY', 'CI', 'CIEN', 'CINF', 'CIR', 'CIT', 'CKH', 'CKPT', 'CL', 'CLAR', 'CLBK', 'CLBS', 'CLCT', 'CLDR', 'CLDX', 'CLF', 'CLFD', 'CLGX', 'CLH', 'CLNE', 'CLPS', 'CLR', 'CLSD', 'CLSN', 'CLVS', 'CLW', 'CLX', 'CLXT', 'CM', 'CMA', 'CMBM', 'CMC', 'CMCO', 'CMCSA', 'CMD', 'CME', 'CMG', 'CMI', 'CMLS', 'CMP', 'CMS', 'CMTL', 'CNA', 'CNBKA', 'CNC', 'CNCE', 'CNDT', 'CNI', 'CNK', 'CNMD', 'CNNE', 'CNO', 'CNOB', 'CNP', 'CNQ', 'CNR', 'CNS', 'CNSL', 'CNST', 'CNX', 'CNXN', 'CO', 'COF', 'COG', 'COHR', 'COHU', 'COKE', 'COLB', 'COLL', 'COLM', 'COMM', 'CONN', 'COO', 'COOP', 'COP', 'CORE', 'CORT', 'COST', 'COT', 'COTY', 'COUP', 'CP', 'CPA', 'CPB', 'CPE', 'CPF', 'CPG', 'CPIX', 'CPK', 'CPRI', 'CPRT', 'CPRX', 'CPS', 'CPSI', 'CPST', 'CR', 'CRAI', 'CRBP', 'CRC', 'CRCM', 'CREE', 'CRI', 'CRIS', 'CRK', 'CRL', 'CRM', 'CRMD', 'CRMT', 'CRNC', 'CRNT', 'CRNX', 'CRON', 'CROX', 'CRS', 'CRTX', 'CRUS', 'CRVL', 'CRVS', 'CRWD', 'CRWS', 'CRY', 'CSBR', 'CSCO', 'CSFL', 'CSGP', 'CSGS', 'CSII', 'CSIQ', 'CSL', 'CSOD', 'CSPI', 'CSS', 'CSSE', 'CSTL', 'CSU', 'CSV', 'CSWI', 'CSX', 'CTAS', 'CTB', 'CTBI', 'CTG', 'CTIC', 'CTL', 'CTLT', 'CTMX', 'CTO', 'CTRA', 'CTRN', 'CTS', 'CTSH', 'CTSO', 'CTVA', 'CTXS', 'CUB', 'CUBI', 'CULP', 'CURO', 'CUTR', 'CVA', 'CVBF', 'CVCO', 'CVE', 'CVET', 'CVGW', 'CVI', 'CVLT', 'CVLY', 'CVM', 'CVNA', 'CVS', 'CVTI', 'CVU', 'CVX', 'CW', 'CWBC', 'CWCO', 'CWEN', 'CWH', 'CWK', 'CWST', 'CWT', 'CXDC', 'CXO', 'CY', 'CYAN', 'CYBE', 'CYBR', 'CYCN', 'CYD', 'CYH', 'CYRX', 'CYTK', 'CZNC', 'CZR', 'CZWI', 'CZZ', 'D', 'DAIO', 'DAKT', 'DAL', 'DAN', 'DAR', 'DARE', 'DB', 'DBD', 'DBI', 'DBX', 'DCI', 'DCO', 'DCOM', 'DCPH', 'DD', 'DDD', 'DDOG', 'DDS', 'DE', 'DECK', 'DELL', 'DENN', 'DERM', 'DFIN', 'DFS', 'DG', 'DGICA', 'DGII', 'DGLY', 'DGX', 'DHI', 'DHIL', 'DHR', 'DHT', 'DIN', 'DIOD', 'DIS', 'DISCA', 'DISCK', 'DISH', 'DJCO', 'DK', 'DKS', 'DLA', 'DLB', 'DLTR', 'DLX', 'DMRC', 'DNKN', 'DNLI', 'DNOW', 'DNR', 'DO', 'DOCU', 'DOMO', 'DOOR', 'DORM', 'DOV', 'DOW', 'DPLO', 'DPZ', 'DRAD', 'DRI', 'DRNA', 'DRQ', 'DSGX', 'DSKE', 'DSPG', 'DT', 'DTE', 'DTIL', 'DUK', 'DVA', 'DVAX', 'DVD', 'DVN', 'DXC', 'DXCM', 'DXPE', 'DXR', 'DY', 'DZSI', 'EA', 'EAF', 'EAT', 'EB', 'EBAY', 'EBF', 'EBIX', 'EBS', 'EBSB', 'EBTC', 'ECHO', 'ECL', 'ECOL', 'ECOM', 'ECPG', 'ED', 'EDIT', 'EDSA', 'EDTX', 'EDUC', 'EE', 'EEFT', 'EEX', 'EFC', 'EFSC', 'EFX', 'EGAN', 'EGBN', 'EGHT', 'EGO', 'EGOV', 'EGRX', 'EGY', 'EHC', 'EHTH', 'EIDX', 'EIG', 'EIGI', 'EIGR', 'EIX', 'EKSO', 'EL', 'ELAN', 'ELF', 'ELGX', 'ELY', 'EMCF', 'EME', 'EMKR', 'EML', 'EMMS', 'EMN', 'EMR', 'ENB', 'ENDP', 'ENLV', 'ENPH', 'ENR', 'ENS', 'ENSG', 'ENTA', 'ENTG', 'ENV', 'ENVA', 'EOG', 'EOLS', 'EPAC', 'EPAM', 'EPAY', 'EPC', 'EPIX', 'EPM', 'EPZM', 'EQH', 'EQT', 'ERA', 'ERF', 'ERI', 'ERIE', 'ERII', 'ES', 'ESCA', 'ESE', 'ESGR', 'ESLT', 'ESNT', 'ESPR', 'ESSA', 'ETFC', 'ETH', 'ETM', 'ETN', 'ETNB', 'ETR', 'ETSY', 'EV', 'EVBG', 'EVC', 'EVER', 'EVFM', 'EVH', 'EVOP', 'EVR', 'EVRG', 'EVRI', 'EW', 'EWBC', 'EXAS', 'EXC', 'EXEL', 'EXK', 'EXLS', 'EXP', 'EXPD', 'EXPE', 'EXPI', 'EXPO', 'EXPR', 'EXTR', 'EYE', 'EYPT', 'EZPW', 'F', 'FAF', 'FANG', 'FARM', 'FARO', 'FAST', 'FAT', 'FATE', 'FB', 'FBC', 'FBHS', 'FBIZ', 'FBK', 'FBM', 'FBMS', 'FBNC', 'FC', 'FCBC', 'FCEL', 'FCF', 'FCFS', 'FCN', 'FCNCA', 'FCX', 'FDEF', 'FDP', 'FDS', 'FDX', 'FE', 'FEIM', 'FELE', 'FEYE', 'FF', 'FFBC', 'FFG', 'FFIC', 'FFIN', 'FFIV', 'FFWM', 'FG', 'FGEN', 'FHB', 'FHN', 'FIBK', 'FICO', 'FII', 'FIS', 'FISI', 'FISV', 'FIT', 'FITB', 'FIVE', 'FIVN', 'FIX', 'FIXX', 'FIZZ', 'FL', 'FLDM', 'FLEX', 'FLGT', 'FLIC', 'FLIR', 'FLMN', 'FLNT', 'FLO', 'FLOW', 'FLR', 'FLS', 'FLT', 'FLWS', 'FLXN', 'FLXS', 'FMBH', 'FMBI', 'FMC', 'FMNB', 'FN', 'FNB', 'FND', 'FNF', 'FNHC', 'FNJN', 'FNKO', 'FNLC', 'FNV', 'FOCS', 'FOE', 'FOLD', 'FOMX', 'FONR', 'FOR', 'FORM', 'FORR', 'FOSL', 'FOX', 'FOXA', 'FOXF', 'FPRX', 'FRAN', 'FRC', 'FREQ', 'FRGI', 'FRHC', 'FRME', 'FRO', 'FRPH', 'FRPT', 'FRTA', 'FSB', 'FSBW', 'FSCT', 'FSFG', 'FSI', 'FSLR', 'FSLY', 'FSM', 'FSS', 'FSTR', 'FTCH', 'FTDR', 'FTEK', 'FTI', 'FTNT', 'FTR', 'FTS', 'FTSV', 'FTV', 'FUL', 'FULC', 'FULT', 'FVE', 'FVRR', 'FWONA', 'FWRD', 'GABC', 'GALT', 'GATX', 'GBCI', 'GBL', 'GBLI', 'GBT', 'GBX', 'GCAP', 'GCBC', 'GCI', 'GCO', 'GCP', 'GD', 'GDDY', 'GDEN', 'GDI', 'GDOT', 'GE', 'GEC', 'GEF', 'GEOS', 'GERN', 'GES', 'GEVO', 'GFF', 'GGG', 'GH', 'GHC', 'GHL', 'GHM', 'GIB', 'GIFI', 'GIII', 'GIL', 'GILD', 'GIS', 'GKOS', 'GL', 'GLDD', 'GLMD', 'GLNG', 'GLRE', 'GLT', 'GLUU', 'GLW', 'GLYC', 'GM', 'GME', 'GMED', 'GMS', 'GNC', 'GNCA', 'GNE', 'GNMK', 'GNMX', 'GNRC', 'GNTX', 'GNW', 'GO', 'GOGO', 'GOLD', 'GOLF', 'GOOG', 'GOOGL', 'GOOS', 'GORO', 'GOSS', 'GPC', 'GPI', 'GPK', 'GPN', 'GPOR', 'GPRE', 'GPRK', 'GPRO', 'GPS', 'GPX', 'GRA', 'GRBK', 'GRC', 'GRIF', 'GRPN', 'GRTS', 'GRUB', 'GS', 'GSB', 'GSBC', 'GSHD', 'GSKY', 'GT', 'GTES', 'GTHX', 'GTLS', 'GTN', 'GTT', 'GTX', 'GVA', 'GWB', 'GWRE', 'GWRS', 'GWW', 'H', 'HA', 'HABT', 'HAE', 'HAFC', 'HAIN', 'HAL', 'HALO', 'HARP', 'HAS', 'HAYN', 'HBAN', 'HBB', 'HBCP', 'HBI', 'HBIO', 'HBM', 'HBNC', 'HBT', 'HCA', 'HCAT', 'HCC', 'HCCI', 'HCI', 'HCKT', 'HCSG', 'HD', 'HDS', 'HDSN', 'HE', 'HEAR', 'HEES', 'HEI', 'HELE', 'HEPA', 'HES', 'HFBL', 'HFC', 'HFFG', 'HFWA', 'HGV', 'HHC', 'HHS', 'HI', 'HIBB', 'HIFS', 'HIG', 'HII', 'HIIQ', 'HJLI', 'HL', 'HLF', 'HLI', 'HLIO', 'HLIT', 'HLT', 'HLX', 'HMHC', 'HMN', 'HMST', 'HMSY', 'HMTV', 'HNGR', 'HNI', 'HOFT', 'HOG', 'HOLX', 'HOMB', 'HOME', 'HON', 'HONE', 'HOPE', 'HOV', 'HP', 'HPE', 'HPQ', 'HQY', 'HRB', 'HRC', 'HRI', 'HRL', 'HROW', 'HRTG', 'HRTX', 'HSC', 'HSIC', 'HSII', 'HSKA', 'HSTM', 'HSY', 'HTBI', 'HTBK', 'HTGM', 'HTH', 'HTLD', 'HTLF', 'HUBB', 'HUBG', 'HUBS', 'HUD', 'HUM', 'HUN', 'HURC', 'HURN', 'HVT', 'HWC', 'HWCC', 'HWKN', 'HXL', 'HY', 'HYRE', 'HZO', 'IAA', 'IAC', 'IAG', 'IART', 'IBCP', 'IBKC', 'IBKR', 'IBM', 'IBOC', 'IBP', 'IBTX', 'ICBK', 'ICE', 'ICFI', 'ICHR', 'ICON', 'ICPT', 'ICUI', 'IDA', 'IDCC', 'IDRA', 'IDT', 'IDXX', 'IESC', 'IEX', 'IFF', 'IGMS', 'IGT', 'IHC', 'IIIN', 'IIIV', 'IIVI', 'ILMN', 'IMAX', 'IMGN', 'IMH', 'IMKTA', 'IMMR', 'IMMU', 'IMUX', 'IMXI', 'INAP', 'INBK', 'INCY', 'INDB', 'INFN', 'INFO', 'INGN', 'INGR', 'INMD', 'INO', 'INOD', 'INOV', 'INS', 'INSG', 'INSM', 'INSP', 'INST', 'INT', 'INTC', 'INTL', 'INTU', 'INVA', 'INVE', 'IO', 'IONS', 'IOSP', 'IOTS', 'IOVA', 'IP', 'IPAR', 'IPG', 'IPGP', 'IPHI', 'IPHS', 'IPI', 'IPWR', 'IQV', 'IR', 'IRBT', 'IRDM', 'IRMD', 'IRTC', 'IRWD', 'ISBC', 'ISEE', 'ISNS', 'ISRG', 'IT', 'ITCI', 'ITGR', 'ITIC', 'ITRI', 'ITT', 'ITW', 'IVC', 'IVZ', 'J', 'JACK', 'JAZZ', 'JBHT', 'JBL', 'JBLU', 'JBSS', 'JBT', 'JCI', 'JCOM', 'JCP', 'JEF', 'JELD', 'JILL', 'JJSF', 'JKHY', 'JLL', 'JNCE', 'JNJ', 'JNPR', 'JOE', 'JOUT', 'JPM', 'JRVR', 'JVA', 'JWN', 'JYNT', 'K', 'KAI', 'KALA', 'KALU', 'KALV', 'KAMN', 'KAR', 'KBH', 'KBR', 'KDMN', 'KDP', 'KE', 'KELYA', 'KEM', 'KEX', 'KEY', 'KEYS', 'KFRC', 'KFS', 'KFY', 'KGC', 'KHC', 'KIDS', 'KIRK', 'KL', 'KLAC', 'KLIC', 'KMB', 'KMI', 'KMPR', 'KMT', 'KMX', 'KN', 'KNDI', 'KNL', 'KNSA', 'KNSL', 'KNX', 'KO', 'KOD', 'KODK', 'KOP', 'KOPN', 'KOS', 'KPTI', 'KR', 'KRA', 'KRNT', 'KRNY', 'KRO', 'KRTX', 'KRUS', 'KRYS', 'KSS', 'KSU', 'KTB', 'KTCC', 'KTOS', 'KURA', 'KVHI', 'KW', 'KWR', 'L', 'LAD', 'LAKE', 'LANC', 'LASR', 'LAUR', 'LAWS', 'LB', 'LBAI', 'LBC', 'LBRDA', 'LBRDK', 'LBRT', 'LBTYA', 'LBTYK', 'LBY', 'LC', 'LCI', 'LCII', 'LCNB', 'LCUT', 'LDL', 'LDOS', 'LE', 'LEA', 'LEAF', 'LECO', 'LEG', 'LEGH', 'LEN', 'LEVI', 'LFUS', 'LFVN', 'LGIH', 'LGND', 'LH', 'LHCG', 'LHX', 'LII', 'LILA', 'LILAK', 'LIN', 'LINC', 'LIND', 'LITE', 'LIVE', 'LIVN', 'LJPC', 'LKFN', 'LKQ', 'LL', 'LLNW', 'LLY', 'LM', 'LMAT', 'LMNR', 'LMNX', 'LMT', 'LNC', 'LNDC', 'LNG', 'LNN', 'LNT', 'LNTH', 'LOB', 'LOCO', 'LOGC', 'LOGM', 'LOOP', 'LOPE', 'LORL', 'LOVE', 'LOW', 'LPCN', 'LPI', 'LPLA', 'LPSN', 'LPX', 'LQDA', 'LQDT', 'LRCX', 'LRN', 'LSCC', 'LSTR', 'LTHM', 'LTRPA', 'LTS', 'LULU', 'LUNA', 'LUV', 'LVGO', 'LVS', 'LW', 'LWAY', 'LXRX', 'LXU', 'LYFT', 'LYTS', 'LYV', 'LZB', 'M', 'MA', 'MACK', 'MAGS', 'MAN', 'MANH', 'MANT', 'MANU', 'MAR', 'MARA', 'MAS', 'MASI', 'MAT', 'MATW', 'MATX', 'MAXR', 'MBI', 'MBIN', 'MBIO', 'MBOT', 'MBUU', 'MBWM', 'MC', 'MCD', 'MCF', 'MCHP', 'MCHX', 'MCK', 'MCO', 'MCRB', 'MCRI', 'MCS', 'MCY', 'MD', 'MDB', 'MDC', 'MDGL', 'MDLA', 'MDLZ', 'MDP', 'MDRX', 'MDT', 'MDU', 'MDWD', 'MEC', 'MED', 'MEDP', 'MEET', 'MEI', 'MELI', 'MEOH', 'MERC', 'MESA', 'MET', 'MFC', 'MFIN', 'MFSF', 'MG', 'MGA', 'MGEE', 'MGI', 'MGIC', 'MGLN', 'MGM', 'MGNX', 'MGPI', 'MGRC', 'MGTA', 'MGTX', 'MGY', 'MHK', 'MHO', 'MIC', 'MIDD', 'MIK', 'MIME', 'MINI', 'MIRM', 'MIST', 'MITK', 'MKC', 'MKL', 'MKSI', 'MKTX', 'MLAB', 'MLHR', 'MLI', 'MLM', 'MLND', 'MLNT', 'MLNX', 'MLR', 'MMC', 'MMM', 'MMS', 'MMSI', 'MMYT', 'MNI', 'MNK', 'MNKD', 'MNLO', 'MNOV', 'MNRO', 'MNST', 'MNTA', 'MO', 'MOBL', 'MOD', 'MODN', 'MOFG', 'MOH', 'MORF', 'MORN', 'MOS', 'MOV', 'MPAA', 'MPC', 'MPWR', 'MPX', 'MRAM', 'MRC', 'MRCY', 'MRIN', 'MRK', 'MRKR', 'MRLN', 'MRNA', 'MRNS', 'MRO', 'MRTN', 'MRTX', 'MRVL', 'MS', 'MSA', 'MSBI', 'MSCI', 'MSEX', 'MSFT', 'MSG', 'MSGN', 'MSI', 'MSM', 'MSON', 'MSTR', 'MTB', 'MTBC', 'MTCH', 'MTD', 'MTDR', 'MTEM', 'MTEX', 'MTG', 'MTH', 'MTN', 'MTOR', 'MTRN', 'MTRX', 'MTSC', 'MTSI', 'MTW', 'MTX', 'MTZ', 'MU', 'MUR', 'MUSA', 'MUX', 'MVIS', 'MWA', 'MXIM', 'MXL', 'MYE', 'MYGN', 'MYL', 'MYOK', 'MYOV', 'MYRG', 'NAII', 'NAT', 'NATH', 'NATI', 'NATR', 'NAV', 'NAVI', 'NBEV', 'NBHC', 'NBIX', 'NBL', 'NBR', 'NBSE', 'NBTB', 'NC', 'NCBS', 'NCLH', 'NCMI', 'NCR', 'NDAQ', 'NDLS', 'NDSN', 'NEE', 'NEM', 'NEO', 'NEOG', 'NEON', 'NEP', 'NERV', 'NET', 'NETE', 'NEU', 'NEWR', 'NEXT', 'NFBK', 'NFE', 'NFG', 'NFLX', 'NG', 'NGHC', 'NGM', 'NGS', 'NGVC', 'NGVT', 'NHC', 'NHTC', 'NI', 'NJR', 'NK', 'NKE', 'NKSH', 'NKTR', 'NL', 'NLNK', 'NLOK', 'NLSN', 'NLTX', 'NMIH', 'NMRK', 'NNBR', 'NNI', 'NOC', 'NOV', 'NOVA', 'NOVN', 'NOVT', 'NOW', 'NP', 'NPK', 'NPO', 'NPTN', 'NR', 'NRC', 'NRG', 'NRIM', 'NSC', 'NSIT', 'NSP', 'NSSC', 'NSTG', 'NTAP', 'NTB', 'NTCT', 'NTGR', 'NTLA', 'NTNX', 'NTR', 'NTRA', 'NTRS', 'NTUS', 'NTWK', 'NUAN', 'NUE', 'NUS', 'NUVA', 'NVAX', 'NVCN', 'NVCR', 'NVDA', 'NVEC', 'NVEE', 'NVMI', 'NVR', 'NVRO', 'NVST', 'NVTA', 'NWBI', 'NWE', 'NWFL', 'NWHM', 'NWL', 'NWLI', 'NWN', 'NWPX', 'NWS', 'NWSA', 'NX', 'NXGN', 'NXPI', 'NXST', 'NXTC', 'NYCB', 'NYT', 'OAS', 'OBCI', 'OBNK', 'OC', 'OCFC', 'OCGN', 'OCN', 'OCUL', 'ODC', 'ODFL', 'ODP', 'ODT', 'OFIX', 'OFLX', 'OGE', 'OGS', 'OI', 'OII', 'OIS', 'OKE', 'OKTA', 'OLED', 'OLLI', 'OLN', 'OMC', 'OMCL', 'OMER', 'OMEX', 'OMF', 'OMI', 'ON', 'ONB', 'ONCS', 'ONCT', 'ONDK', 'ONTO', 'ONTX', 'OOMA', 'OPB', 'OPES', 'OPGN', 'OPK', 'OPRT', 'OPTN', 'OPTT', 'OPY', 'ORA', 'ORBC', 'ORCC', 'ORCL', 'ORI', 'ORLY', 'ORMP', 'ORRF', 'OSIS', 'OSK', 'OSPN', 'OSTK', 'OSUR', 'OTEX', 'OTIC', 'OTTR', 'OVV', 'OXM', 'OXY', 'OZK', 'P', 'PAAS', 'PACB', 'PACQ', 'PACW', 'PAG', 'PAGP', 'PAGS', 'PAH', 'PAHC', 'PANW', 'PAR', 'PARR', 'PATK', 'PAYC', 'PAYS', 'PAYX', 'PB', 'PBCT', 'PBF', 'PBH', 'PBI', 'PBPB', 'PBYI', 'PCAR', 'PCG', 'PCOM', 'PCRX', 'PCTI', 'PCTY', 'PCYG', 'PD', 'PDCE', 'PDCO', 'PDFS', 'PDLI', 'PE', 'PEBO', 'PEG', 'PEGA', 'PEGI', 'PEIX', 'PEN', 'PENN', 'PEP', 'PERI', 'PETQ', 'PETS', 'PFBC', 'PFBI', 'PFE', 'PFG', 'PFGC', 'PFIS', 'PFNX', 'PFPT', 'PFS', 'PFSI', 'PFSW', 'PG', 'PGC', 'PGNX', 'PGNY', 'PGR', 'PGTI', 'PH', 'PHAS', 'PHAT', 'PHM', 'PHR', 'PHX', 'PI', 'PICO', 'PII', 'PINC', 'PING', 'PINS', 'PIR', 'PIRS', 'PJT', 'PKE', 'PKG', 'PKI', 'PKOH', 'PLAB', 'PLAN', 'PLAY', 'PLCE', 'PLIN', 'PLMR', 'PLNT', 'PLOW', 'PLPC', 'PLSE', 'PLT', 'PLUG', 'PLUS', 'PLXP', 'PLXS', 'PLYA', 'PM', 'PMD', 'PME', 'PNC', 'PNFP', 'PNM', 'PNR', 'PNRG', 'PNTG', 'PNW', 'PODD', 'POL', 'POOL', 'POR', 'POST', 'POWI', 'POWL', 'PPBI', 'PPC', 'PPG', 'PPIH', 'PPL', 'PPSI', 'PQG', 'PRA', 'PRAA', 'PRAH', 'PRCP', 'PRFT', 'PRGO', 'PRGS', 'PRI', 'PRIM', 'PRK', 'PRLB', 'PRMW', 'PRNB', 'PRO', 'PROS', 'PROV', 'PRPL', 'PRSC', 'PRSP', 'PRTA', 'PRTK', 'PRTY', 'PRU', 'PRVB', 'PRVL', 'PS', 'PSMT', 'PSN', 'PSNL', 'PSTG', 'PSTI', 'PSTV', 'PSX', 'PTC', 'PTCT', 'PTEN', 'PTGX', 'PTI', 'PTLA', 'PTON', 'PTSI', 'PTVCB', 'PUB', 'PUMP', 'PVG', 'PVH', 'PWOD', 'PWR', 'PXD', 'PXLW', 'PYPL', 'PZN', 'PZZA', 'QADA', 'QCOM', 'QCRH', 'QDEL', 'QEP', 'QLYS', 'QNST', 'QRTEA', 'QRVO', 'QSR', 'QTRX', 'QTWO', 'QUAD', 'QUIK', 'QUMU', 'QUOT', 'R', 'RACE', 'RAD', 'RADA', 'RAIL', 'RAMP', 'RAPT', 'RARE', 'RAVE', 'RAVN', 'RBA', 'RBBN', 'RBC', 'RBCAA', 'RBCN', 'RCI', 'RCII', 'RCKT', 'RCKY', 'RCL', 'RCM', 'RCUS', 'RDFN', 'RDI', 'RDN', 'RDNT', 'RDUS', 'RDWR', 'RE', 'REAL', 'RECN', 'REGI', 'REGN', 'RELL', 'REPH', 'REPL', 'RES', 'RESN', 'RETA', 'REV', 'REVG', 'REX', 'REZI', 'RF', 'RFIL', 'RFL', 'RFP', 'RGA', 'RGEN', 'RGLD', 'RGNX', 'RGR', 'RGS', 'RH', 'RHI', 'RICK', 'RILY', 'RIOT', 'RJF', 'RL', 'RLGY', 'RLH', 'RLI', 'RM', 'RMAX', 'RMBS', 'RMCF', 'RMD', 'RMNI', 'RMR', 'RMTI', 'RNET', 'RNG', 'RNR', 'RNST', 'RNWK', 'ROCK', 'ROG', 'ROK', 'ROKU', 'ROL', 'ROLL', 'ROP', 'ROST', 'RP', 'RPAY', 'RPD', 'RPM', 'RRC', 'RRD', 'RRGB', 'RRR', 'RRTS', 'RS', 'RSG', 'RST', 'RTIX', 'RTN', 'RTRX', 'RUBI', 'RUBY', 'RUN', 'RUSHA', 'RUTH', 'RVLV', 'RVNC', 'RWLK', 'RXN', 'RY', 'RYI', 'RYTM', 'S', 'SA', 'SABR', 'SAFM', 'SAFT', 'SAGE', 'SAH', 'SAIA', 'SAIC', 'SAIL', 'SAM', 'SANM', 'SANW', 'SASR', 'SATS', 'SAVE', 'SBCF', 'SBGI', 'SBH', 'SBNY', 'SBPH', 'SBSI', 'SBT', 'SBUX', 'SC', 'SCCO', 'SCHL', 'SCHN', 'SCHW', 'SCI', 'SCKT', 'SCL', 'SCOR', 'SCPL', 'SCS', 'SCSC', 'SCU', 'SCVL', 'SCWX', 'SCX', 'SDC', 'SDRL', 'SEAS', 'SEB', 'SEDG', 'SEE', 'SEIC', 'SEM', 'SENEA', 'SERV', 'SF', 'SFBS', 'SFE', 'SFIX', 'SFM', 'SFNC', 'SG', 'SGA', 'SGBX', 'SGC', 'SGEN', 'SGH', 'SGMO', 'SGMS', 'SGRY', 'SGU', 'SHAK', 'SHEN', 'SHLD', 'SHLO', 'SHOO', 'SHOP', 'SHW', 'SIBN', 'SIEN', 'SIF', 'SIG', 'SIGA', 'SIGI', 'SILK', 'SINA', 'SINT', 'SIRI', 'SITE', 'SIVB', 'SIX', 'SJI', 'SJM', 'SJR', 'SJW', 'SKX', 'SKY', 'SKYW', 'SLAB', 'SLB', 'SLCA', 'SLCT', 'SLDB', 'SLF', 'SLGG', 'SLGN', 'SLM', 'SLP', 'SLRX', 'SM', 'SMAR', 'SMBC', 'SMED', 'SMG', 'SMMF', 'SMP', 'SMPL', 'SMTC', 'SMTX', 'SNA', 'SNAP', 'SNBR', 'SNCR', 'SND', 'SNDX', 'SNOA', 'SNPS', 'SNSS', 'SNV', 'SNX', 'SO', 'SOI', 'SON', 'SONM', 'SONO', 'SORL', 'SP', 'SPAR', 'SPB', 'SPCE', 'SPFI', 'SPGI', 'SPKE', 'SPLK', 'SPN', 'SPNE', 'SPNS', 'SPOK', 'SPOT', 'SPPI', 'SPR', 'SPSC', 'SPTN', 'SPWR', 'SPXC', 'SQ', 'SR', 'SRAX', 'SRCE', 'SRCL', 'SRDX', 'SRE', 'SRI', 'SRL', 'SRPT', 'SRRK', 'SSB', 'SSD', 'SSI', 'SSNC', 'SSP', 'SSRM', 'SSTI', 'SSTK', 'SSYS', 'ST', 'STAA', 'STBA', 'STC', 'STE', 'STFC', 'STIM', 'STL', 'STLD', 'STMP', 'STNE', 'STOK', 'STRA', 'STRL', 'STRO', 'STRS', 'STRT', 'STSA', 'STT', 'STX', 'STZ', 'SU', 'SUM', 'SUP', 'SUPN', 'SVMK', 'SWAV', 'SWCH', 'SWIR', 'SWK', 'SWKS', 'SWM', 'SWN', 'SWTX', 'SWX', 'SXC', 'SXI', 'SXT', 'SYBT', 'SYBX', 'SYF', 'SYK', 'SYKE', 'SYNA', 'SYNC', 'SYNH', 'SYRS', 'SYX', 'SYY', 'T', 'TA', 'TACO', 'TACT', 'TALO', 'TAP', 'TARA', 'TARO', 'TAST', 'TBBK', 'TBI', 'TBIO', 'TBK', 'TBNK', 'TBPH', 'TCBI', 'TCBK', 'TCDA', 'TCMD', 'TCON', 'TCRR', 'TCS', 'TCX', 'TD', 'TDC', 'TDG', 'TDOC', 'TDS', 'TDW', 'TDY', 'TEAM', 'TECD', 'TECH', 'TECK', 'TEL', 'TELL', 'TEN', 'TENB', 'TER', 'TERP', 'TESS', 'TEX', 'TFC', 'TFSL', 'TFX', 'TG', 'TGE', 'TGEN', 'TGH', 'TGI', 'TGLS', 'TGNA', 'TGP', 'TGT', 'TGTX', 'THC', 'THFF', 'THG', 'THMO', 'THO', 'THR', 'THRM', 'THS', 'TIF', 'TILE', 'TISI', 'TIVO', 'TJX', 'TKKS', 'TKR', 'TLRA', 'TLRD', 'TLRY', 'TLYS', 'TMHC', 'TMO', 'TMP', 'TMST', 'TMUS', 'TNAV', 'TNC', 'TNDM', 'TNET', 'TNP', 'TOL', 'TORC', 'TOWN', 'TPC', 'TPCO', 'TPH', 'TPIC', 'TPR', 'TPRE', 'TPTX', 'TPX', 'TR', 'TRC', 'TREE', 'TREX', 'TRGP', 'TRHC', 'TRI', 'TRIP', 'TRMB', 'TRMK', 'TRN', 'TROW', 'TROX', 'TRP', 'TRQ', 'TRS', 'TRST', 'TRT', 'TRTN', 'TRU', 'TRUE', 'TRUP', 'TRV', 'TRWH', 'TRXC', 'TSC', 'TSCO', 'TSEM', 'TSG', 'TSLA', 'TSN', 'TSQ', 'TSRI', 'TTC', 'TTD', 'TTEC', 'TTEK', 'TTGT', 'TTMI', 'TTOO', 'TTPH', 'TTWO', 'TUFN', 'TUP', 'TUSK', 'TVTY', 'TW', 'TWIN', 'TWLO', 'TWNK', 'TWOU', 'TWST', 'TWTR', 'TXG', 'TXMD', 'TXN', 'TXRH', 'TXT', 'TYL', 'TZOO', 'UAA', 'UAL', 'UBER', 'UBSI', 'UBX', 'UCBI', 'UCTT', 'UEIC', 'UFCS', 'UFI', 'UFPI', 'UFPT', 'UFS', 'UG', 'UGI', 'UHAL', 'UHS', 'UI', 'UIHC', 'UIS', 'ULBI', 'ULH', 'ULTA', 'UMBF', 'UMPQ', 'UNB', 'UNF', 'UNFI', 'UNH', 'UNM', 'UNP', 'UNT', 'UNVR', 'UPLD', 'UPS', 'UPWK', 'URBN', 'URGN', 'URI', 'UROV', 'USAK', 'USAP', 'USAS', 'USB', 'USCR', 'USFD', 'USLM', 'USM', 'USNA', 'USPH', 'USX', 'UTHR', 'UTI', 'UTL', 'UTMD', 'UTSI', 'UTX', 'UVE', 'UVSP', 'UVV', 'V', 'VAC', 'VAL', 'VALU', 'VAPO', 'VAR', 'VBTX', 'VC', 'VCEL', 'VCNX', 'VCRA', 'VCYT', 'VEC', 'VECO', 'VEEV', 'VERI', 'VERU', 'VFC', 'VGR', 'VHI', 'VIAC', 'VIAV', 'VICR', 'VIE', 'VIR', 'VIRT', 'VIVE', 'VIVO', 'VKTX', 'VLGEA', 'VLO', 'VLY', 'VMC', 'VMI', 'VMW', 'VNCE', 'VNDA', 'VNE', 'VOXX', 'VOYA', 'VPG', 'VRA', 'VRAY', 'VRCA', 'VREX', 'VRNS', 'VRNT', 'VRRM', 'VRS', 'VRSK', 'VRSN', 'VRTS', 'VRTU', 'VRTV', 'VRTX', 'VSAT', 'VSEC', 'VSH', 'VSLR', 'VST', 'VSTO', 'VUZI', 'VVI', 'VVUS', 'VVV', 'VYGR', 'VZ', 'W', 'WAB', 'WABC', 'WAFD', 'WAL', 'WASH', 'WAT', 'WATT', 'WBA', 'WBS', 'WBT', 'WCC', 'WCN', 'WD', 'WDAY', 'WDC', 'WDFC', 'WDR', 'WEC', 'WEN', 'WERN', 'WETF', 'WEX', 'WEYS', 'WFC', 'WGO', 'WH', 'WHD', 'WHG', 'WHR', 'WIFI', 'WINA', 'WING', 'WINS', 'WIRE', 'WIX', 'WK', 'WLDN', 'WLFC', 'WLH', 'WLK', 'WLL', 'WLTW', 'WM', 'WMB', 'WMK', 'WMS', 'WMT', 'WNC', 'WNEB', 'WOR', 'WORK', 'WORX', 'WOW', 'WPM', 'WPRT', 'WPX', 'WRB', 'WRK', 'WRLD', 'WRTC', 'WSBC', 'WSBF', 'WSC', 'WSFS', 'WSM', 'WSO', 'WST', 'WTBA', 'WTFC', 'WTI', 'WTM', 'WTR', 'WTRE', 'WTS', 'WU', 'WVE', 'WVFC', 'WVVI', 'WW', 'WWD', 'WWE', 'WWR', 'WWW', 'WYND', 'WYNN', 'X', 'XAIR', 'XBIT', 'XEC', 'XEL', 'XENE', 'XENT', 'XLNX', 'XLRN', 'XNCR', 'XOG', 'XOM', 'XOMA', 'XON', 'XONE', 'XPEL', 'XPER', 'XPO', 'XRAY', 'XRX', 'XYL', 'Y', 'YELP', 'YETI', 'YEXT', 'YMAB', 'YNDX', 'YORW', 'YRCW', 'YUM', 'YUMA', 'YUMC', 'ZAGG', 'ZBH', 'ZBRA', 'ZEN', 'ZFGN', 'ZG', 'ZGNX', 'ZION', 'ZIOP', 'ZIXI', 'ZM', 'ZNGA', 'ZS', 'ZTS', 'ZUMZ', 'ZUO', 'ZVO', 'ZYME', 'ZYNE']\n"
     ]
    }
   ],
   "source": [
    "ticker_file = open(\"ticker.txt\")\n",
    "data = ticker_file.readlines()\n",
    "ticker_file.close()\n",
    "\n",
    "ticker_list = [i.rstrip('\\n') for i in data]\n",
    "\n",
    "print(len(ticker_list))\n",
    "print(ticker_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.stocktwits.com/api/2/streams/symbol/BBRY.json\n",
      "./data/BBRY_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/AAPL.json\n",
      "./data/AAPL_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/AMZN.json\n",
      "./data/AMZN_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/BABA.json\n",
      "./data/BABA_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/YHOO.json\n",
      "./data/YHOO_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/FB.json\n",
      "./data/FB_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/GOOG.json\n",
      "./data/GOOG_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/BBBY.json\n",
      "./data/BBBY_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/JNUG.json\n",
      "./data/JNUG_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/SBUX.json\n",
      "./data/SBUX_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/MU.json\n",
      "./data/MU_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/MRVL.json\n",
      "./data/MRVL_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/ADMA.json\n",
      "./data/ADMA_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/HIG.json\n",
      "./data/HIG_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/LGND.json\n",
      "./data/LGND_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/DORM.json\n",
      "./data/DORM_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/GIB.json\n",
      "./data/GIB_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/SIEN.json\n",
      "./data/SIEN_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/NFE.json\n",
      "./data/NFE_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/CSFL.json\n",
      "./data/CSFL_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/LM.json\n",
      "./data/LM_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/CERN.json\n",
      "./data/CERN_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/NEE.json\n",
      "./data/NEE_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/FULC.json\n",
      "./data/FULC_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/SGBX.json\n",
      "./data/SGBX_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/TROW.json\n",
      "./data/TROW_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/CWBC.json\n",
      "./data/CWBC_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/TFC.json\n",
      "./data/TFC_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/SBSI.json\n",
      "./data/SBSI_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/DGLY.json\n",
      "./data/DGLY_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/KODK.json\n",
      "./data/KODK_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/BLD.json\n",
      "./data/BLD_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/REZI.json\n",
      "./data/REZI_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/MOS.json\n",
      "./data/MOS_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/SRAX.json\n",
      "./data/SRAX_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/PRA.json\n",
      "./data/PRA_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/CTL.json\n",
      "./data/CTL_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/COLB.json\n",
      "./data/COLB_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/EFC.json\n",
      "./data/EFC_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/BBY.json\n",
      "./data/BBY_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/DK.json\n",
      "./data/DK_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/JILL.json\n",
      "./data/JILL_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/IIIV.json\n",
      "./data/IIIV_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/AJG.json\n",
      "./data/AJG_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/OCGN.json\n",
      "./data/OCGN_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/JBL.json\n",
      "./data/JBL_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/ALG.json\n",
      "./data/ALG_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/PSN.json\n",
      "./data/PSN_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/WYND.json\n",
      "./data/WYND_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/MRNA.json\n",
      "./data/MRNA_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/ABG.json\n",
      "./data/ABG_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/ACIA.json\n",
      "./data/ACIA_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/VRA.json\n",
      "./data/VRA_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/CSS.json\n",
      "./data/CSS_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/SPAR.json\n",
      "./data/SPAR_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/CZNC.json\n",
      "./data/CZNC_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/GWB.json\n",
      "./data/GWB_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/BRKL.json\n",
      "./data/BRKL_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/UTMD.json\n",
      "./data/UTMD_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/MRIN.json\n",
      "./data/MRIN_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/BZH.json\n",
      "./data/BZH_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/WMS.json\n",
      "./data/WMS_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/SNV.json\n",
      "./data/SNV_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/DBD.json\n",
      "./data/DBD_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/LNN.json\n",
      "./data/LNN_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/FBIZ.json\n",
      "./data/FBIZ_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/RBBN.json\n",
      "./data/RBBN_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/SWCH.json\n",
      "./data/SWCH_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/INVA.json\n",
      "./data/INVA_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/AN.json\n",
      "./data/AN_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/FBHS.json\n",
      "./data/FBHS_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/CDAY.json\n",
      "./data/CDAY_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/PNFP.json\n",
      "./data/PNFP_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/EPAM.json\n",
      "./data/EPAM_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/SCI.json\n",
      "./data/SCI_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/VYGR.json\n",
      "./data/VYGR_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/DFS.json\n",
      "./data/DFS_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/FSLY.json\n",
      "./data/FSLY_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/SSRM.json\n",
      "./data/SSRM_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/NEOG.json\n",
      "./data/NEOG_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/QLYS.json\n",
      "./data/QLYS_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/CHMA.json\n",
      "./data/CHMA_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/ANF.json\n",
      "./data/ANF_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/CSTL.json\n",
      "./data/CSTL_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/HMHC.json\n",
      "./data/HMHC_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/ADES.json\n",
      "./data/ADES_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/CORT.json\n",
      "./data/CORT_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/EYE.json\n",
      "./data/EYE_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/KFY.json\n",
      "./data/KFY_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/RNWK.json\n",
      "./data/RNWK_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/JJSF.json\n",
      "./data/JJSF_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/CRK.json\n",
      "./data/CRK_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/MANT.json\n",
      "./data/MANT_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/IMMR.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/IMMR_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/ADUS.json\n",
      "./data/ADUS_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/AR.json\n",
      "./data/AR_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/ATO.json\n",
      "./data/ATO_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/NRC.json\n",
      "./data/NRC_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/BCC.json\n",
      "./data/BCC_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/MATX.json\n",
      "./data/MATX_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/CZZ.json\n",
      "./data/CZZ_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/ADS.json\n",
      "./data/ADS_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/LFUS.json\n",
      "./data/LFUS_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/ENVA.json\n",
      "./data/ENVA_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/WIRE.json\n",
      "./data/WIRE_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/PTEN.json\n",
      "./data/PTEN_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/CDW.json\n",
      "./data/CDW_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/PCTY.json\n",
      "./data/PCTY_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/TOL.json\n",
      "./data/TOL_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/ATRC.json\n",
      "./data/ATRC_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/AEE.json\n",
      "./data/AEE_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/TRI.json\n",
      "./data/TRI_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/PINC.json\n",
      "./data/PINC_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/INFN.json\n",
      "./data/INFN_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/TELL.json\n",
      "./data/TELL_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/MTDR.json\n",
      "./data/MTDR_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/SAIC.json\n",
      "./data/SAIC_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/EBIX.json\n",
      "./data/EBIX_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/LCI.json\n",
      "./data/LCI_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/VNE.json\n",
      "./data/VNE_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/YUMA.json\n",
      "./data/YUMA_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/CCS.json\n",
      "./data/CCS_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/SCSC.json\n",
      "./data/SCSC_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/COP.json\n",
      "./data/COP_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/BCOR.json\n",
      "./data/BCOR_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/PLCE.json\n",
      "./data/PLCE_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/CSWI.json\n",
      "./data/CSWI_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/ISEE.json\n",
      "./data/ISEE_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/FARM.json\n",
      "./data/FARM_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/ECOM.json\n",
      "./data/ECOM_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/CSPI.json\n",
      "./data/CSPI_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/CSIQ.json\n",
      "./data/CSIQ_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/HAE.json\n",
      "./data/HAE_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/CORE.json\n",
      "./data/CORE_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/RMD.json\n",
      "./data/RMD_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/BLBD.json\n",
      "./data/BLBD_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/QTWO.json\n",
      "./data/QTWO_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/XRAY.json\n",
      "./data/XRAY_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/ABEO.json\n",
      "./data/ABEO_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/CO.json\n",
      "./data/CO_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/VERI.json\n",
      "./data/VERI_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/PLOW.json\n",
      "./data/PLOW_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/DELL.json\n",
      "./data/DELL_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/TDG.json\n",
      "./data/TDG_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/BNFT.json\n",
      "./data/BNFT_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/GBX.json\n",
      "./data/GBX_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/PRGO.json\n",
      "./data/PRGO_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/MLND.json\n",
      "./data/MLND_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/AVNS.json\n",
      "./data/AVNS_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/OFLX.json\n",
      "./data/OFLX_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/DBI.json\n",
      "./data/DBI_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/FIZZ.json\n",
      "./data/FIZZ_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/DDS.json\n",
      "./data/DDS_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/ALGN.json\n",
      "./data/ALGN_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/LLY.json\n",
      "./data/LLY_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/IO.json\n",
      "./data/IO_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/CWT.json\n",
      "./data/CWT_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/MDT.json\n",
      "./data/MDT_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/CYD.json\n",
      "./data/CYD_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/CYH.json\n",
      "./data/CYH_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/SLDB.json\n",
      "./data/SLDB_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/WLK.json\n",
      "./data/WLK_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/FND.json\n",
      "./data/FND_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/MPWR.json\n",
      "./data/MPWR_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/PTLA.json\n",
      "./data/PTLA_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/XBIT.json\n",
      "./data/XBIT_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/MSCI.json\n",
      "./data/MSCI_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/INBK.json\n",
      "./data/INBK_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/CDK.json\n",
      "./data/CDK_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/AVY.json\n",
      "./data/AVY_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/UIHC.json\n",
      "./data/UIHC_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/OFIX.json\n",
      "./data/OFIX_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/DRAD.json\n",
      "./data/DRAD_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/TRQ.json\n",
      "./data/TRQ_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/TNDM.json\n",
      "./data/TNDM_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/SLCA.json\n",
      "./data/SLCA_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/EBS.json\n",
      "./data/EBS_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/CLDX.json\n",
      "./data/CLDX_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/REX.json\n",
      "./data/REX_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/FBMS.json\n",
      "./data/FBMS_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/INVE.json\n",
      "./data/INVE_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/SINT.json\n",
      "./data/SINT_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/HCAT.json\n",
      "./data/HCAT_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/CFFI.json\n",
      "./data/CFFI_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/RNET.json\n",
      "./data/RNET_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/PSMT.json\n",
      "./data/PSMT_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/XNCR.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/XNCR_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/WAFD.json\n",
      "./data/WAFD_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/ATH.json\n",
      "./data/ATH_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/FTR.json\n",
      "./data/FTR_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/MYOK.json\n",
      "./data/MYOK_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/AOS.json\n",
      "./data/AOS_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/LBY.json\n",
      "./data/LBY_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/PZZA.json\n",
      "./data/PZZA_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/RLI.json\n",
      "./data/RLI_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/SMED.json\n",
      "./data/SMED_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/CAG.json\n",
      "./data/CAG_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/TRU.json\n",
      "./data/TRU_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/AVYA.json\n",
      "./data/AVYA_20200207_0459.json\n",
      "https://api.stocktwits.com/api/2/streams/symbol/CREE.json\n",
      "./data/CREE_20200207_0459.json\n"
     ]
    }
   ],
   "source": [
    "symbols = ['BBRY', 'AAPL', 'AMZN', 'BABA', 'YHOO', 'FB', 'GOOG', 'BBBY', 'JNUG', 'SBUX', 'MU']\n",
    "\n",
    "NUM_REQUEST = 200 - len(symbols)\n",
    "\n",
    "random.seed(12345)\n",
    "symbols.extend(random.sample(ticker_list, NUM_REQUEST))\n",
    "\n",
    "args = ['curl', '-X', 'GET', '']\n",
    "URL = \"https://api.stocktwits.com/api/2/streams/symbol/\"\n",
    "\n",
    "FILE_PATH = \"./data/\"\n",
    "\n",
    "start_datetime = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "for symbol in symbols:\n",
    "    try:\n",
    "        args[3] = URL + symbol + \".json\"\n",
    "        print(args[3])\n",
    "        proc = subprocess.run(args,stdout = subprocess.PIPE, stderr = subprocess.PIPE)\n",
    "\n",
    "        path = FILE_PATH + symbol + \"_\" + start_datetime + \".json\"\n",
    "        print(path)\n",
    "        with open(path, mode='w') as f:\n",
    "            f.write(proc.stdout.decode(\"utf8\"))\n",
    "    except:\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正常なレスポンス・ステータスを持っていないファイルを取り除きます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/INBK_20200207_0459.json\r\n",
      "data/CSWI_20200207_0459.json\r\n"
     ]
    }
   ],
   "source": [
    "!grep -rlv '{\"response\":{\"status\":200}' data\n",
    "!grep -rlv '{\"response\":{\"status\":200}' data | xargs rm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、保存したファイルを、分散処理環境（クラスター）を使って加工するためにHDFSへコピーします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export HADOOP_CONF_DIR=/etc/hadoop/conf; hdfs dfs -mkdir ./twits/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export HADOOP_CONF_DIR=/etc/hadoop/conf; hdfs dfs -put ./data/* ./twits/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 198 items\r\n",
      "-rw-r--r--   3 admin supergroup      40135 2020-02-07 05:31 twits/AAPL_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      34640 2020-02-07 05:31 twits/ABEO_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      56001 2020-02-07 05:31 twits/ABG_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      48370 2020-02-07 05:31 twits/ACIA_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      53569 2020-02-07 05:31 twits/ADES_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      34594 2020-02-07 05:31 twits/ADMA_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      48297 2020-02-07 05:31 twits/ADS_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      50407 2020-02-07 05:31 twits/ADUS_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      51851 2020-02-07 05:31 twits/AEE_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      50550 2020-02-07 05:31 twits/AJG_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      42060 2020-02-07 05:31 twits/ALGN_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      49800 2020-02-07 05:31 twits/ALG_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      49161 2020-02-07 05:31 twits/AMZN_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      46221 2020-02-07 05:31 twits/ANF_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      48460 2020-02-07 05:31 twits/AN_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      49702 2020-02-07 05:31 twits/AOS_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      36485 2020-02-07 05:31 twits/AR_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      48520 2020-02-07 05:31 twits/ATH_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      44486 2020-02-07 05:31 twits/ATO_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      49966 2020-02-07 05:31 twits/ATRC_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      48301 2020-02-07 05:31 twits/AVNS_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      46056 2020-02-07 05:31 twits/AVYA_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      50822 2020-02-07 05:31 twits/AVY_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      45012 2020-02-07 05:31 twits/BABA_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      40999 2020-02-07 05:31 twits/BBBY_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      39657 2020-02-07 05:31 twits/BBRY_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      49929 2020-02-07 05:31 twits/BBY_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      49865 2020-02-07 05:31 twits/BCC_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      48299 2020-02-07 05:31 twits/BCOR_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      51337 2020-02-07 05:31 twits/BLBD_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      51003 2020-02-07 05:31 twits/BLD_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      35063 2020-02-07 05:31 twits/BNFT_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      48007 2020-02-07 05:31 twits/BRKL_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      50982 2020-02-07 05:31 twits/BZH_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      47368 2020-02-07 05:31 twits/CAG_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      49179 2020-02-07 05:31 twits/CCS_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      46167 2020-02-07 05:31 twits/CDAY_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      46341 2020-02-07 05:31 twits/CDK_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      45622 2020-02-07 05:31 twits/CDW_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      50266 2020-02-07 05:31 twits/CERN_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      51589 2020-02-07 05:31 twits/CFFI_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      36519 2020-02-07 05:31 twits/CHMA_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      36453 2020-02-07 05:31 twits/CLDX_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      50312 2020-02-07 05:31 twits/COLB_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      48289 2020-02-07 05:31 twits/COP_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      57494 2020-02-07 05:31 twits/CORE_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      46132 2020-02-07 05:31 twits/CORT_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      38756 2020-02-07 05:31 twits/CO_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      44417 2020-02-07 05:31 twits/CREE_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      37877 2020-02-07 05:31 twits/CRK_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      49715 2020-02-07 05:31 twits/CSFL_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      35407 2020-02-07 05:31 twits/CSIQ_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      45653 2020-02-07 05:31 twits/CSPI_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      44123 2020-02-07 05:31 twits/CSS_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      45979 2020-02-07 05:31 twits/CSTL_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      37772 2020-02-07 05:31 twits/CTL_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      49766 2020-02-07 05:31 twits/CWBC_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      56857 2020-02-07 05:31 twits/CWT_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      53393 2020-02-07 05:31 twits/CYD_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      41293 2020-02-07 05:31 twits/CYH_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      53484 2020-02-07 05:31 twits/CZNC_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      44871 2020-02-07 05:31 twits/CZZ_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      52542 2020-02-07 05:31 twits/DBD_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      48655 2020-02-07 05:31 twits/DBI_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      57579 2020-02-07 05:31 twits/DDS_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      40811 2020-02-07 05:31 twits/DELL_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      39767 2020-02-07 05:31 twits/DFS_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      33123 2020-02-07 05:31 twits/DGLY_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      46294 2020-02-07 05:31 twits/DK_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      49149 2020-02-07 05:31 twits/DORM_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      36090 2020-02-07 05:31 twits/DRAD_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      43542 2020-02-07 05:31 twits/EBIX_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      48426 2020-02-07 05:31 twits/EBS_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      51606 2020-02-07 05:31 twits/ECOM_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      52007 2020-02-07 05:31 twits/EFC_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      46790 2020-02-07 05:31 twits/ENVA_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      50440 2020-02-07 05:31 twits/EPAM_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      51266 2020-02-07 05:31 twits/EYE_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      48986 2020-02-07 05:31 twits/FARM_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      50016 2020-02-07 05:31 twits/FBHS_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      49372 2020-02-07 05:31 twits/FBIZ_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      53098 2020-02-07 05:31 twits/FBMS_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      43861 2020-02-07 05:31 twits/FB_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      47015 2020-02-07 05:31 twits/FIZZ_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      49714 2020-02-07 05:31 twits/FND_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      37330 2020-02-07 05:31 twits/FSLY_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      35557 2020-02-07 05:31 twits/FTR_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      44246 2020-02-07 05:31 twits/FULC_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      45028 2020-02-07 05:31 twits/GBX_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      47097 2020-02-07 05:31 twits/GIB_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      51243 2020-02-07 05:31 twits/GOOG_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      49037 2020-02-07 05:31 twits/GWB_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      48041 2020-02-07 05:31 twits/HAE_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      44039 2020-02-07 05:31 twits/HCAT_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      47302 2020-02-07 05:31 twits/HIG_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      46790 2020-02-07 05:31 twits/HMHC_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      42348 2020-02-07 05:31 twits/IIIV_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      38396 2020-02-07 05:31 twits/IMMR_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      40438 2020-02-07 05:31 twits/INFN_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      48757 2020-02-07 05:31 twits/INVA_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      46091 2020-02-07 05:31 twits/INVE_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      44074 2020-02-07 05:31 twits/IO_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      34896 2020-02-07 05:31 twits/ISEE_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      44926 2020-02-07 05:31 twits/JBL_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      32091 2020-02-07 05:31 twits/JILL_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      52260 2020-02-07 05:31 twits/JJSF_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      38933 2020-02-07 05:31 twits/JNUG_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      49940 2020-02-07 05:31 twits/KFY_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      45012 2020-02-07 05:31 twits/KODK_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      38227 2020-02-07 05:31 twits/LBY_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      36784 2020-02-07 05:31 twits/LCI_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      48117 2020-02-07 05:31 twits/LFUS_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      46619 2020-02-07 05:31 twits/LGND_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      40471 2020-02-07 05:31 twits/LLY_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      47849 2020-02-07 05:31 twits/LM_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      48229 2020-02-07 05:31 twits/LNN_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      57305 2020-02-07 05:31 twits/MANT_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      51090 2020-02-07 05:31 twits/MATX_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      45805 2020-02-07 05:31 twits/MDT_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      46861 2020-02-07 05:31 twits/MLND_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      43627 2020-02-07 05:31 twits/MOS_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      48566 2020-02-07 05:31 twits/MPWR_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      39006 2020-02-07 05:31 twits/MRIN_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      43654 2020-02-07 05:31 twits/MRNA_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      40214 2020-02-07 05:31 twits/MRVL_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      45317 2020-02-07 05:31 twits/MSCI_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      49623 2020-02-07 05:31 twits/MTDR_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      44953 2020-02-07 05:31 twits/MU_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      46746 2020-02-07 05:31 twits/MYOK_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      41972 2020-02-07 05:31 twits/NEE_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      47664 2020-02-07 05:31 twits/NEOG_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      51997 2020-02-07 05:31 twits/NFE_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      45605 2020-02-07 05:31 twits/NRC_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      36897 2020-02-07 05:31 twits/OCGN_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      55672 2020-02-07 05:31 twits/OFIX_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      56279 2020-02-07 05:31 twits/OFLX_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      42860 2020-02-07 05:31 twits/PCTY_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      50124 2020-02-07 05:31 twits/PINC_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      51639 2020-02-07 05:31 twits/PLCE_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      48575 2020-02-07 05:31 twits/PLOW_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      51359 2020-02-07 05:31 twits/PNFP_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      49195 2020-02-07 05:31 twits/PRA_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      49786 2020-02-07 05:31 twits/PRGO_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      51179 2020-02-07 05:31 twits/PSMT_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      49971 2020-02-07 05:31 twits/PSN_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      49713 2020-02-07 05:31 twits/PTEN_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      40367 2020-02-07 05:31 twits/PTLA_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      44942 2020-02-07 05:31 twits/PZZA_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      48756 2020-02-07 05:31 twits/QLYS_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      49723 2020-02-07 05:31 twits/QTWO_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      38700 2020-02-07 05:31 twits/RBBN_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      54265 2020-02-07 05:31 twits/REX_20200207_0459.json\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--   3 admin supergroup      44154 2020-02-07 05:31 twits/REZI_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      48815 2020-02-07 05:31 twits/RLI_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      47491 2020-02-07 05:31 twits/RMD_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      48705 2020-02-07 05:31 twits/RNET_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      42964 2020-02-07 05:31 twits/RNWK_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      51350 2020-02-07 05:31 twits/SAIC_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      47672 2020-02-07 05:31 twits/SBSI_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      37341 2020-02-07 05:31 twits/SBUX_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      46350 2020-02-07 05:31 twits/SCI_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      49072 2020-02-07 05:31 twits/SCSC_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      31558 2020-02-07 05:31 twits/SGBX_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      30534 2020-02-07 05:31 twits/SIEN_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      35046 2020-02-07 05:31 twits/SINT_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      39269 2020-02-07 05:31 twits/SLCA_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      35302 2020-02-07 05:31 twits/SLDB_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      44121 2020-02-07 05:31 twits/SMED_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      49819 2020-02-07 05:31 twits/SNV_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      47748 2020-02-07 05:31 twits/SPAR_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      44569 2020-02-07 05:31 twits/SRAX_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      48809 2020-02-07 05:31 twits/SSRM_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      43586 2020-02-07 05:31 twits/SWCH_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      44687 2020-02-07 05:31 twits/TDG_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      49633 2020-02-07 05:31 twits/TELL_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      39061 2020-02-07 05:31 twits/TFC_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      37521 2020-02-07 05:31 twits/TNDM_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      50441 2020-02-07 05:31 twits/TOL_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      52343 2020-02-07 05:31 twits/TRI_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      49900 2020-02-07 05:31 twits/TROW_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      38309 2020-02-07 05:31 twits/TRQ_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      47977 2020-02-07 05:31 twits/TRU_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      56702 2020-02-07 05:31 twits/UIHC_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      46619 2020-02-07 05:31 twits/UTMD_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      33897 2020-02-07 05:31 twits/VERI_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      47607 2020-02-07 05:31 twits/VNE_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      49059 2020-02-07 05:31 twits/VRA_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      43462 2020-02-07 05:31 twits/VYGR_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      49856 2020-02-07 05:31 twits/WAFD_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      53742 2020-02-07 05:31 twits/WIRE_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      49354 2020-02-07 05:31 twits/WLK_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      49115 2020-02-07 05:31 twits/WMS_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      54700 2020-02-07 05:31 twits/WYND_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      44299 2020-02-07 05:31 twits/XBIT_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      54990 2020-02-07 05:31 twits/XNCR_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      50262 2020-02-07 05:31 twits/XRAY_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      45482 2020-02-07 05:31 twits/YHOO_20200207_0459.json\r\n",
      "-rw-r--r--   3 admin supergroup      35672 2020-02-07 05:31 twits/YUMA_20200207_0459.json\r\n"
     ]
    }
   ],
   "source": [
    "!export HADOOP_CONF_DIR=/etc/hadoop/conf; hdfs dfs -ls ./twits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ変換\n",
    "\n",
    "クラスターでデータを変換します。CDSW上では、ユーザーごとに別のプロジェクトを使っていましたが、クラスター環境では、自分が利用しているユーザーとデータを意識して取り扱う必要があります。\n",
    "\n",
    "\n",
    "あなたの（HADOOPクラスターへアクセスする）ユーザ名は以下で確認できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "admin\r\n"
     ]
    }
   ],
   "source": [
    "!echo $HADOOP_USER_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データベースの準備\n",
    "\n",
    "\n",
    "\n",
    "**下記のセルの中を適切なユーザ名とURL（Hiveサーバー）に置換してください。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**下記のセルの中を適切なユーザ名とURL（Hiveサーバー）に置換してください。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Connected: admin@None'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql hive://admin@master.ykono.work:10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**あなたのユーザ名でデータベースを作成・利用してください**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * hive://admin@master.ykono.work:10000\n",
      "(pyhive.exc.OperationalError) TExecuteStatementResp(status=TStatus(statusCode=3, infoMessages=['*org.apache.hive.service.cli.HiveSQLException:Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. Database admin already exists:29:28', 'org.apache.hive.service.cli.operation.Operation:toSQLException:Operation.java:329', 'org.apache.hive.service.cli.operation.SQLOperation:runQuery:SQLOperation.java:258', 'org.apache.hive.service.cli.operation.SQLOperation:runInternal:SQLOperation.java:293', 'org.apache.hive.service.cli.operation.Operation:run:Operation.java:260', 'org.apache.hive.service.cli.session.HiveSessionImpl:executeStatementInternal:HiveSessionImpl.java:505', 'org.apache.hive.service.cli.session.HiveSessionImpl:executeStatement:HiveSessionImpl.java:480', 'sun.reflect.NativeMethodAccessorImpl:invoke0:NativeMethodAccessorImpl.java:-2', 'sun.reflect.NativeMethodAccessorImpl:invoke:NativeMethodAccessorImpl.java:62', 'sun.reflect.DelegatingMethodAccessorImpl:invoke:DelegatingMethodAccessorImpl.java:43', 'java.lang.reflect.Method:invoke:Method.java:498', 'org.apache.hive.service.cli.session.HiveSessionProxy:invoke:HiveSessionProxy.java:78', 'org.apache.hive.service.cli.session.HiveSessionProxy:access$000:HiveSessionProxy.java:36', 'org.apache.hive.service.cli.session.HiveSessionProxy$1:run:HiveSessionProxy.java:63', 'java.security.AccessController:doPrivileged:AccessController.java:-2', 'javax.security.auth.Subject:doAs:Subject.java:422', 'org.apache.hadoop.security.UserGroupInformation:doAs:UserGroupInformation.java:1875', 'org.apache.hive.service.cli.session.HiveSessionProxy:invoke:HiveSessionProxy.java:59', 'com.sun.proxy.$Proxy37:executeStatement::-1', 'org.apache.hive.service.cli.CLIService:executeStatement:CLIService.java:270', 'org.apache.hive.service.cli.thrift.ThriftCLIService:ExecuteStatement:ThriftCLIService.java:508', 'org.apache.hive.service.rpc.thrift.TCLIService$Processor$ExecuteStatement:getResult:TCLIService.java:1437', 'org.apache.hive.service.rpc.thrift.TCLIService$Processor$ExecuteStatement:getResult:TCLIService.java:1422', 'org.apache.thrift.ProcessFunction:process:ProcessFunction.java:39', 'org.apache.thrift.TBaseProcessor:process:TBaseProcessor.java:39', 'org.apache.hive.service.auth.TSetIpAddressProcessor:process:TSetIpAddressProcessor.java:56', 'org.apache.thrift.server.TThreadPoolServer$WorkerProcess:run:TThreadPoolServer.java:286', 'java.util.concurrent.ThreadPoolExecutor:runWorker:ThreadPoolExecutor.java:1149', 'java.util.concurrent.ThreadPoolExecutor$Worker:run:ThreadPoolExecutor.java:624', 'java.lang.Thread:run:Thread.java:748', '*org.apache.hadoop.hive.ql.metadata.HiveException:Database admin already exists:37:9', 'org.apache.hadoop.hive.ql.exec.DDLTask:createDatabase:DDLTask.java:4198', 'org.apache.hadoop.hive.ql.exec.DDLTask:execute:DDLTask.java:308', 'org.apache.hadoop.hive.ql.exec.Task:executeTask:Task.java:199', 'org.apache.hadoop.hive.ql.exec.TaskRunner:runSequential:TaskRunner.java:97', 'org.apache.hadoop.hive.ql.Driver:launchTask:Driver.java:2200', 'org.apache.hadoop.hive.ql.Driver:execute:Driver.java:1843', 'org.apache.hadoop.hive.ql.Driver:runInternal:Driver.java:1563', 'org.apache.hadoop.hive.ql.Driver:run:Driver.java:1339', 'org.apache.hadoop.hive.ql.Driver:run:Driver.java:1334', 'org.apache.hive.service.cli.operation.SQLOperation:runQuery:SQLOperation.java:256', '*org.apache.hadoop.hive.metastore.api.AlreadyExistsException:Database admin already exists:57:20', 'org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$create_database_result$create_database_resultStandardScheme:read:ThriftHiveMetastore.java:26211', 'org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$create_database_result$create_database_resultStandardScheme:read:ThriftHiveMetastore.java:26197', 'org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$create_database_result:read:ThriftHiveMetastore.java:26131', 'org.apache.thrift.TServiceClient:receiveBase:TServiceClient.java:86', 'org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client:recv_create_database:ThriftHiveMetastore.java:741', 'org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client:create_database:ThriftHiveMetastore.java:728', 'org.apache.hadoop.hive.metastore.HiveMetaStoreClient:createDatabase:HiveMetaStoreClient.java:800', 'sun.reflect.NativeMethodAccessorImpl:invoke0:NativeMethodAccessorImpl.java:-2', 'sun.reflect.NativeMethodAccessorImpl:invoke:NativeMethodAccessorImpl.java:62', 'sun.reflect.DelegatingMethodAccessorImpl:invoke:DelegatingMethodAccessorImpl.java:43', 'java.lang.reflect.Method:invoke:Method.java:498', 'org.apache.hadoop.hive.metastore.RetryingMetaStoreClient:invoke:RetryingMetaStoreClient.java:154', 'com.sun.proxy.$Proxy36:createDatabase::-1', 'sun.reflect.NativeMethodAccessorImpl:invoke0:NativeMethodAccessorImpl.java:-2', 'sun.reflect.NativeMethodAccessorImpl:invoke:NativeMethodAccessorImpl.java:62', 'sun.reflect.DelegatingMethodAccessorImpl:invoke:DelegatingMethodAccessorImpl.java:43', 'java.lang.reflect.Method:invoke:Method.java:498', 'org.apache.hadoop.hive.metastore.HiveMetaStoreClient$SynchronizedHandler:invoke:HiveMetaStoreClient.java:2562', 'com.sun.proxy.$Proxy36:createDatabase::-1', 'org.apache.hadoop.hive.ql.metadata.Hive:createDatabase:Hive.java:433', 'org.apache.hadoop.hive.ql.exec.DDLTask:createDatabase:DDLTask.java:4194'], sqlState='42000', errorCode=1, errorMessage='Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. Database admin already exists'), operationHandle=None)\n",
      "[SQL: CREATE DATABASE admin]\n",
      "(Background on this error at: http://sqlalche.me/e/e3q8)\n",
      " * hive://admin@master.ykono.work:10000\n",
      "Done.\n",
      " * hive://admin@master.ykono.work:10000\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>tab_name</th>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql CREATE DATABASE admin\n",
    "%sql USE admin\n",
    "%sql SHOW TABLES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ライブラリファイルのコピー・登録\n",
    "\n",
    "Hiveクエリの中でjsonファイルを扱えるようにするためのライブラリを登録します。\n",
    "ライブラリファイルはGithubリポジトリに含まれています（ライブラリの詳細は`/lib/README.jar`を参照ください）。\n",
    "はじめにCDSWからHDFSにコピーし、HDFS上のファイルをHiveへ登録します。\n",
    "\n",
    "コンパイル済みのライブラリファイルをリポジトリに含めています。\n",
    "- json-1.3.7.3.jar\n",
    "- json-serde-cdh5-shim-1.3.7.3.jar\n",
    "- json-serde-1.3.7.3.jar'\n",
    "\n",
    "- brickhouse-0.7.1-SNAPSHOT.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "put: `brickhouse-0.7.1-SNAPSHOT.jar': File exists\n",
      "put: `json-1.3.7.3.jar': File exists\n",
      "put: `json-serde-1.3.7.3.jar': File exists\n",
      "put: `json-serde-cdh5-shim-1.3.7.3.jar': File exists\n",
      "Found 5 items\n",
      "-rw-r--r--   3 admin supergroup     308146 2020-02-07 05:14 brickhouse-0.7.1-SNAPSHOT.jar\n",
      "-rw-r--r--   3 admin supergroup      44477 2020-02-07 05:14 json-1.3.7.3.jar\n",
      "-rw-r--r--   3 admin supergroup      36653 2020-02-07 05:14 json-serde-1.3.7.3.jar\n",
      "-rw-r--r--   3 admin supergroup       5110 2020-02-07 05:14 json-serde-cdh5-shim-1.3.7.3.jar\n",
      "drwxr-xr-x   - admin supergroup          0 2020-02-07 05:13 twits\n"
     ]
    }
   ],
   "source": [
    "!export HADOOP_CONF_DIR=/etc/hadoop/conf; hdfs dfs -put `ls -1 ./lib/*.jar` .; hdfs dfs -ls ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**下記のパスを適切なユーザ名で置換してください。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * hive://admin@master.ykono.work:10000\n",
      "Done.\n",
      " * hive://admin@master.ykono.work:10000\n",
      "Done.\n",
      " * hive://admin@master.ykono.work:10000\n",
      "Done.\n",
      " * hive://admin@master.ykono.work:10000\n",
      "Done.\n",
      " * hive://admin@master.ykono.work:10000\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql add jar hdfs:/user/admin/json-1.3.7.3.jar\n",
    "%sql add jar hdfs:/user/admin/json-serde-1.3.7.3.jar\n",
    "%sql add jar hdfs:/user/admin/json-serde-cdh5-shim-1.3.7.3.jar\n",
    "%sql add jar hdfs:/user/admin/brickhouse-0.7.1-SNAPSHOT.jar\n",
    "%sql CREATE TEMPORARY FUNCTION to_json AS 'brickhouse.udf.json.ToJsonUDF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * hive://admin@master.ykono.work:10000\n",
      "Done.\n",
      " * hive://admin@master.ykono.work:10000\n",
      "Done.\n",
      " * hive://admin@master.ykono.work:10000\n",
      "Done.\n",
      " * hive://admin@master.ykono.work:10000\n",
      "Done.\n",
      " * hive://admin@master.ykono.work:10000\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql DROP TABLE IF EXISTS twits\n",
    "%sql DROP TABLE IF EXISTS message_extracted\n",
    "%sql DROP TABLE IF EXISTS message_filtered\n",
    "%sql DROP TABLE IF EXISTS message_exploded\n",
    "%sql DROP TABLE IF EXISTS sentiment_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SNSメッセージファイルを格納した場所を指定して、テーブルを作成します。\n",
    "\n",
    "**`LOCATION`指定にあなたがファイルをアップロードしたパスを指定してください**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * hive://admin@master.ykono.work:10000\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "CREATE EXTERNAL TABLE twits (\n",
    "\tmessages \n",
    "\tARRAY<\n",
    "\t    STRUCT<body: STRING,\n",
    "\t        symbols:ARRAY<STRUCT<symbol:STRING>>,\n",
    "\t        entities:STRUCT<sentiment:STRUCT<basic:STRING>>\n",
    "\t    >\n",
    "\t>\n",
    ")\n",
    "ROW FORMAT SERDE 'org.openx.data.jsonserde.JsonSerDe' \n",
    "STORED AS TEXTFILE\n",
    "LOCATION '/user/admin/twits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * hive://admin@master.ykono.work:10000\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>_c0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>198</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(198,)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "select count(*) from twits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * hive://admin@master.ykono.work:10000\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>messages</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>[{&quot;body&quot;:&quot;$AAPL had approximately 2395M USD go to the short side at 52 pct short  Bears and Bulls are fighting close  https://www.algowins.com/?wdt_column_filter[1]=AAPL&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;AAPL&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;$AAPL nice squeeze on the daily. If jobs report goes well 330 tomorrow&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;AAPL&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:{&quot;basic&quot;:&quot;Bullish&quot;}}},{&quot;body&quot;:&quot;In the last month $AAPL has a been trading in the 302.22 - 327.85 range, which is quite wide. https://www.chartmill.com/stock/quote/AAPL/technical-analysis?key=bb853040-a4ac-41c6-b549-d218d2f21b32&amp;amp;utm_source=stocktwits&amp;amp;utm_medium=TA&amp;amp;utm_content=AAPL&amp;amp;utm_campaign=social_tracking&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;AAPL&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;$EROS SEEING IS BELIEVING - EROSNOW IS NOW ON APPLE TV+ AS OF TODAY! \\n \\nThanks @InvesThor  / Waleed. You beat me to this find &amp;amp; I thank you. For those of you that are new to Eros or just may not understand the significance of this then let me tell you. \\n \\nI&amp;#39;ve been checking the Apple plus app every few days for the past few months based on information disclosed by Eros in the last quarterly conference call. They had said that something was cooking with Apple $AAPL but there has been no press release yet. \\n \\nEros mentioned again in las Vegas last month that an Apple business deal was still in the works.  \\n \\nAs we all know in life, people say things but it does not always happen. Well it has happened. It is here. Expect pre paid revenues for Eros off the charts immediately. \\n \\nExpect a press release by tomorrow or Monday am. \\n \\nExpect mainstream mutual funds to jump in. \\n \\nExpect Eros SP to gap back up to at least $8 &amp;amp; then some. \\n \\nBuckle up folks, this is HUUGE!  \\nGLTL!!! Go $EROS&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;AAPL&quot;},{&quot;symbol&quot;:&quot;EROS&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:{&quot;basic&quot;:&quot;Bullish&quot;}}},{&quot;body&quot;:&quot;How I Plan To Trade Tesla Stock https://youtu.be/RLXL4V6J6RE $TSLA 📈 \\n\\nHolding $AAPL and $BYND&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;AAPL&quot;},{&quot;symbol&quot;:&quot;TSLA&quot;},{&quot;symbol&quot;:&quot;BYND&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;$GOOG $GOOGL $MSFT $AAPL $AMZN   \\nT-Birds Performance!&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;AAPL&quot;},{&quot;symbol&quot;:&quot;AMZN&quot;},{&quot;symbol&quot;:&quot;GOOG&quot;},{&quot;symbol&quot;:&quot;MSFT&quot;},{&quot;symbol&quot;:&quot;GOOGL&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:{&quot;basic&quot;:&quot;Bullish&quot;}}},{&quot;body&quot;:&quot;$AAPL Does anyone know what date you need to own shares by in order to get the dividend?&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;AAPL&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;$AAPL \\nWE ALL HAVE A RIGHT TO SAY WHAT WE THINK ABOUT A SPECIFIC STOCK!\\nNO ONE IS DECLARING OR EVEN ASSUMING!\\nIT JUST WOULD NOT SHOCK ME IF SKYROCKETS TOMORROW!!!\\nSIMPLE LOGIC \\nIT BUGS ME THAT SIMPLE LOGIC BUGS PEOPLE&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;AAPL&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:{&quot;basic&quot;:&quot;Bullish&quot;}}},{&quot;body&quot;:&quot;$AAPL $400 by August... seems about right! Undervalued at these levels and at the $400 price target!&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;AAPL&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:{&quot;basic&quot;:&quot;Bullish&quot;}}},{&quot;body&quot;:&quot;$AAPL \\nFOR THE RECORD THERE IS SOMETHING CALLED PRICE TARGET \\nNOT SURE WHAT THAT IS???&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;AAPL&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;$AAPL Less than three dollars from making new ATH&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;AAPL&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:{&quot;basic&quot;:&quot;Bullish&quot;}}},{&quot;body&quot;:&quot;$AAPL \\nPEOPLE WHO HEAR BOMBSHELLS LIKE THIS AND THINK APPLE WILL GO BEARISH IS A LOT MORE DELUSIONAL THAN ONE WHO HAS HIGH HOPES FOR THE STOCK!\\nGOOD TRY!&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;AAPL&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:{&quot;basic&quot;:&quot;Bullish&quot;}}},{&quot;body&quot;:&quot;$AAPL $AMZN $ENPH $TSLA \\nAvailable on Amazon&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;AAPL&quot;},{&quot;symbol&quot;:&quot;AMZN&quot;},{&quot;symbol&quot;:&quot;TSLA&quot;},{&quot;symbol&quot;:&quot;ENPH&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;$AAPL&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;AAPL&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:{&quot;basic&quot;:&quot;Bearish&quot;}}},{&quot;body&quot;:&quot;$AAPL \\n\\nARE YOU FREAKIN KIDDING?\\n💣💣💣💣💣💣💣💣💣💣💣💣💣💣🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥\\n\\nAPPLE STOCK IS NOT WORTH $325.50\\nWITH THIS 2 BOMBSHELLS APPLE MAY SEE ITS MOST GLORIOUS DAY TOMORROW.\\nBOMBSHELL 1-I PHONE 12 LEAKED \\nBOMBSHELL 2-AND CHINA CUTTING TARIFFS IS OFFICIAL!\\n\\n340- 400 would not surprise me at all!!&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;AAPL&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:{&quot;basic&quot;:&quot;Bullish&quot;}}},{&quot;body&quot;:&quot;$AAPL [Feb-07 310.00 Calls] Option volume Up +113.96 % |  Volume: 21,118 vs 9,870 https://www.sleekoptions.com/sleekscan.aspx?sub1=dsc&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;AAPL&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;Peak profit for the last 6 expired option alerts for $AAPL 11.86  | -18.08  | 529.17  | 3.02  | 354.20  | 402.11  |&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;AAPL&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;$AAPL we gold for tomorrow I need another property 🐋🧐🌎💰&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;AAPL&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:{&quot;basic&quot;:&quot;Bullish&quot;}}},{&quot;body&quot;:&quot;$SPY $TSLA $AAPL $AMZN \\n\\nI’m sorry, this just really bugs me. \\n\\nAnyone who says that a stock “will be at (stated price)” is out of their minds and delusional. \\nYou cannot, I repeat, YOU CANNOT say where a security on the short term will be. You’re just telling everyone what you hope it will be based on your position.&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;AAPL&quot;},{&quot;symbol&quot;:&quot;AMZN&quot;},{&quot;symbol&quot;:&quot;SPY&quot;},{&quot;symbol&quot;:&quot;TSLA&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;$AAPL - Exit Apple and check out… http://dlvr.it/RPY5vL #portfolio_prospective #better_portfolio #diversify&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;AAPL&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;$SPY $MCD $AAPL Why stonks only up since 1993\\n\\nEveryone knows this&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;AAPL&quot;},{&quot;symbol&quot;:&quot;MCD&quot;},{&quot;symbol&quot;:&quot;SPY&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:{&quot;basic&quot;:&quot;Bullish&quot;}}},{&quot;body&quot;:&quot;$AAPL half of China is shut down. Schools are shut to mid February. I wonder why schools are closed longer than work?&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;AAPL&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;$AAPL the 24 provinces not working account for 80% of national GDP&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;AAPL&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;$SPY China in a pandemic? Will they be able to buy the new iPhone? $AAPL  so ex dividend is tomorrow?  Long term holders shouldn&amp;#39;t worry but option traders will have some fun tomorrow 😊&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;AAPL&quot;},{&quot;symbol&quot;:&quot;SPY&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;$AAPL \\nREAD HEADLINE OF FORBES CAREFULLY \\n“ACCIDENTALLY LEAKED” (HA, GOOD DECOY)\\nTHIS A ROCKET 🚀 TO THE MOON \\n\\nEDITORS&amp;#39; PICK|9,012 views|Feb 6, 2020,8:00 pm\\nApple “Accidentally Leaks” Radical iPhone Upgrade&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;AAPL&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;$AAPL \\n\\nAnd the potential here is mind boggling. Not just for personal car ownership (where you can already find similar technology in apps from Tesla and others) but as a universal Apple car key across multiple brands for car hire, car sharing and more.&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;AAPL&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;$AAPL \\n\\nStrings of code inside iOS 13.4 explain that CarKey will work just like Apple Pay with a user authenticating via biometrics then holding their iPhone / Apple Watch to a reader in the car&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;AAPL&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;$AAPL \\n\\nPicked up by 9to5Mac, Apple accidentally left code in its newly released iOS 13.4 beta for ‘CarKey’, an unannounced all-new service which has the potential to transform the automotive landscape by enabling iPhone and Apple Watch owners to use their devices as digital car keys.&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;AAPL&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;$AAPL \\nWOW WOW WOW 🤩 \\nCALL ME CRAZY, OR OUT OF MY MIND \\n\\nAPPLE SHOULD GO UP 5-15% Tomorrow \\nMAJOR NEWS COMING\\nAPPLE LEAKED INFO ON I PHONE 12!!!\\nTHIS INFO IS MIND  BLOWING ON WHAT TYPE OF PHONE THIS WILL BE:\\nFORBES FIRST TO REPORT LEAK!\\nALL THE NEWS WILL BE TALKING ABOUT TOMORROW IS THE I PHONE 12!\\n\\nhttps://www.forbes.com/sites/gordonkelly/2020/02/06/apple-iphone-2020-ios-134-carkey-upgrade-iphone-11-pro-max-update/amp/&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;AAPL&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:{&quot;basic&quot;:&quot;Bullish&quot;}}},{&quot;body&quot;:&quot;$AAPL $SPY $ITOT Where is my boy ShortyMcShortDick at tonight? Markets red in looking for some emoji overkill&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;AAPL&quot;},{&quot;symbol&quot;:&quot;SPY&quot;},{&quot;symbol&quot;:&quot;ITOT&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:{&quot;basic&quot;:&quot;Bullish&quot;}}}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>[{&quot;body&quot;:&quot;$ABEO wow not that much activity here.. usually means rocket lovers are selling 👍&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABEO&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:{&quot;basic&quot;:&quot;Bearish&quot;}}},{&quot;body&quot;:&quot;Integrated Core Strategies (us) Llc has filed an amended 13G/A, reporting 4.1% ownership in $ABEO - https://fintel.io/so/us/abeo?utm_source=stocktwits.com&amp;amp;utm_medium=social&amp;amp;utm_campaign=owner&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABEO&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;$ABEO Form SC 13G/A (statement of acquisition of beneficial ownership by individuals) filed with the SEC \\n\\nhttps://newsfilter.io/a/55b43bc8126ab9934aad553997957c67&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABEO&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;$ABEO cranking back up&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABEO&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:{&quot;basic&quot;:&quot;Bullish&quot;}}},{&quot;body&quot;:&quot;$ABEO power our run will be fun&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABEO&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:{&quot;basic&quot;:&quot;Bullish&quot;}}},{&quot;body&quot;:&quot;$ABEO Halted?&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABEO&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:{&quot;basic&quot;:&quot;Bullish&quot;}}},{&quot;body&quot;:&quot;$ABEO Next week will be interesting!&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABEO&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:{&quot;basic&quot;:&quot;Bullish&quot;}}},{&quot;body&quot;:&quot;Short sale volume (not short interest) for $ABEO on 2020-02-05 is 50%. http://shortvolumes.com/?t=ABEO via @shortvolumes&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABEO&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;$VBIV  $abeo&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABEO&quot;},{&quot;symbol&quot;:&quot;VBIV&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:{&quot;basic&quot;:&quot;Bullish&quot;}}},{&quot;body&quot;:&quot;$ABEO Stochastic shows plenty of headroom. It&amp;#39;ll keep climbing. Pretty much a foregone conclusion, as you can see&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABEO&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:{&quot;basic&quot;:&quot;Bullish&quot;}}},{&quot;body&quot;:&quot;$ABEO we drinking la croix tonight...had. A pretty big position here. Big daddy gains this morning&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABEO&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:{&quot;basic&quot;:&quot;Bullish&quot;}}},{&quot;body&quot;:&quot;$ABEO Great volume and nice end of the day close&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABEO&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;$ABEO run eod, lets go&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABEO&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:{&quot;basic&quot;:&quot;Bullish&quot;}}},{&quot;body&quot;:&quot;$ABEO It&amp;#39;s just getting started. The stochastic buy signal first appeared yesterday. Someone must&amp;#39;ve forgotten to tell that Olivergarden bashtard, so he&amp;#39;s back for another ass whooping&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABEO&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:{&quot;basic&quot;:&quot;Bullish&quot;}}},{&quot;body&quot;:&quot;$ABEO Oliverrr? Oliver where are you&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABEO&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;$ABEO pT?&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABEO&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;$ABEO lets break 260 and its good to go&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABEO&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:{&quot;basic&quot;:&quot;Bullish&quot;}}},{&quot;body&quot;:&quot;$ABEO Welcome Back Oliver, I hope you changed your undies 🤣&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABEO&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;$ABEO 2.20s to 2.70s, those guys wont hold this. Just here to scam and swing\\n\\nDont jump this as no news is expected for a long time\\n\\nProtect your cost basis 💥&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABEO&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:{&quot;basic&quot;:&quot;Bearish&quot;}}},{&quot;body&quot;:&quot;$ABEO oh no I see scammers here 💩&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABEO&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:{&quot;basic&quot;:&quot;Bearish&quot;}}},{&quot;body&quot;:&quot;$ABEO Shix, why the huge pullback? Break 2.80, you pig!!&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABEO&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:{&quot;basic&quot;:&quot;Bullish&quot;}}},{&quot;body&quot;:&quot;$MGEN \\n$SVRA \\n$ABEO \\n$ABUS&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;SVRA&quot;},{&quot;symbol&quot;:&quot;ABUS&quot;},{&quot;symbol&quot;:&quot;MGEN&quot;},{&quot;symbol&quot;:&quot;ABEO&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:{&quot;basic&quot;:&quot;Bullish&quot;}}},{&quot;body&quot;:&quot;$ABEO nice morning runs on both ABEO and $CETX. Profit in the morning buy back mid day. Best part is you won’t have to use a daytrade!&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABEO&quot;},{&quot;symbol&quot;:&quot;CETX&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;$ABEO this stock is between 2-3 bucks for months.. if u swing here, it js better than holding for months...\\n\\nI am long so i hold but if u want to swing here, u want to sell on every pop...&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABEO&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:{&quot;basic&quot;:&quot;Bullish&quot;}}},{&quot;body&quot;:&quot;$ABEO let’s move this past 3&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABEO&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:{&quot;basic&quot;:&quot;Bullish&quot;}}},{&quot;body&quot;:&quot;$ABEO daily reminder than I’m just a pumper 👇👇👇.  Definitely don’t buy $ACHV $XBIO $ACST or any of my other bio picks as I have no clue what I’m doing.&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ACHV&quot;},{&quot;symbol&quot;:&quot;ACST&quot;},{&quot;symbol&quot;:&quot;ABEO&quot;},{&quot;symbol&quot;:&quot;XBIO&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:{&quot;basic&quot;:&quot;Bullish&quot;}}},{&quot;body&quot;:&quot;$ABEO on the move today!&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABEO&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:{&quot;basic&quot;:&quot;Bullish&quot;}}},{&quot;body&quot;:&quot;$ABEO i even gave the price watches ;) cant do more . congrats to all my friends who banked on that call with me. 2.17 - 2.75 so far ;).&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABEO&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;$ABEO absolutely beautiful. I am behind baby 100%&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABEO&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:{&quot;basic&quot;:&quot;Bullish&quot;}}},{&quot;body&quot;:&quot;$ABEO 😬👇🏼&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABEO&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>[{&quot;body&quot;:&quot;$ABG reported 9 new insider trades to the SEC in the last 2 minutes.\\n\\n2,222 shares acquired by Stax William Frederick (CAO &amp;amp; Interim PFO)   https://newsfilter.io/articles/4-form-2bd9ea66af5dffa97255d109ffdd8e86\\n$55,387.14 of shares sold by James Juanita T (Director)   https://newsfilter.io/articles/4-form-60e7ba95315d3ae158458e8efa1e9863\\n$250,169.01 of shares sold by Hult David W (President &amp;amp; CEO)   https://newsfilter.io/articles/4-form-3704a40c36d2a6df040a89b09fb87ecc\\n$55,387.14 of shares sold by Ryan Berman Bridget (Director)   https://newsfilter.io/articles/4-form-371b6d2f56d167110fa5ce899a0b76fa\\n$58,065.62 of shares sold by Alsfine Joel (Director)   https://newsfilter.io/articles/4-form-12ae0276c06abb1d01d247617120dd11\\n4,286 shares acquired by Milstein Jed (SVP &amp;amp; CHRO)   https://newsfilter.io/articles/4-form-fd08e9c74c01038f1bbdf2048637a6b3\\n1,411 shares acquired by Deloach Thomas C Jr (Director)   https://newsfilter.io/articles/4-form-7956b6f97d2d28c78017277dd2ab195f\\n1,411 shares acquired by Maritz Philip F (Director)   https://newsfilter.io/articles/4-form-c51c5e658b77854a6f9b9f5ca6a0ce5d\\n$65,986.05 of shares sold by Villasana George A (SVP, GC &amp;amp; Secretary)   https://newsfilter.io/articles/4-form-a130909e55462da17528d0a3a4ea0aff&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABG&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;$ABG filed SEC form 4: SVP, GC &amp;amp; Secretary Villasana George A: \\nDelivered securities 685 of Common Stock at price $96.33 and Acquired 7,16 https://s.flashalert.me/fQwirI&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABG&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;$ABG filed SEC form 4: CAO &amp;amp; Interim PFO Stax William Frederick: \\nGranted 2,222 of Common Stock at price $0 on 2020-02-04, increased holdi https://s.flashalert.me/Ek4nfD&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABG&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;$ABG filed SEC form 4: SVP &amp;amp; CHRO Milstein Jed: \\nGranted 4,286 of Common Stock at price $0 on 2020-02-04, increased holding by 41% to 14,6 https://s.flashalert.me/rXRnu&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABG&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;$ABG filed SEC form 4: SVP, Operations Clara Daniel: \\nGranted 2,091 of Common Stock at price $0 on 2020-02-04, increased holding by 12% to https://s.flashalert.me/OHtFO&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABG&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;$ABG filed SEC form 4: President &amp;amp; CEO Hult David W: \\nDelivered securities 2,597 of Common Stock at price $96.33 and Acquired 20,072 of Co https://s.flashalert.me/WsaB0P&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABG&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;$ABG filed SEC form 4: Director Morrison Maureen F: \\nGranted 1,411 of Common Stock at price $0 on 2020-02-04, increased holding by 116% to https://s.flashalert.me/FEdTfa&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABG&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;$ABG filed SEC form 4: Director RYAN BERMAN BRIDGET: \\nDelivered securities 579 of Common Stock at price $95.66 and Granted 1,411 of Common https://s.flashalert.me/kdafDP&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABG&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;SVP of Asbury Automotive Group Inc just declared owning 16,904 shares of Asbury Automotive Grou http://www.conferencecalltranscripts.org/5/summary2/?id=7386787 $ABG&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABG&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;$ABG filed SEC form 4: Director MARITZ PHILIP F: \\nGranted 1,411 of Common Stock at price $0 on 2020-02-04, increased holding by 16% to 10, https://s.flashalert.me/XE3zHl&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABG&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;$ABG filed SEC form 4: Director Katz Eugene S: \\nDelivered securities 494 of Common Stock at price $95.66 and Granted 1,411 of Common Stock https://s.flashalert.me/JkG1jk&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABG&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;$ABG filed SEC form 4: Director JAMES JUANITA T: \\nDelivered securities 579 of Common Stock at price $95.66 and Granted 1,411 of Common Sto https://s.flashalert.me/uKU5E&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABG&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;$ABG filed SEC form 4: Director DELOACH THOMAS C JR: \\nGranted 1,411 of Common Stock at price $0 on 2020-02-04, increased holding by 9% to  https://s.flashalert.me/fLD4TG&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABG&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;$ABG filed SEC form 4: Director ALSFINE JOEL: \\nDelivered securities 607 of Common Stock at price $95.66 and Granted 1,411 of Common Stock  https://s.flashalert.me/epHIa0&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABG&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;$ABG filed SEC form 4: Director REDDIN THOMAS: \\nGranted 1,411 of Common Stock at price $0 on 2020-02-04, increased holding by 22% to 7,777 https://s.flashalert.me/T1iEF3&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABG&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;$ABG 1,411 shares acquired by Reddin Thomas (Director), reported in a new form 4 filed with the SEC  \\n\\nhttps://newsfilter.io/a/4ffbd7ee2bb2d297ec4c0e39cbc52fd7&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABG&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;$ABG filed SEC form 3: SVP, Operations Clara Daniel: \\n https://s.flashalert.me/RmaSRk&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABG&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;$ABG Form 3 (initial statement of beneficial ownership of securities) filed with the SEC \\n\\nhttps://newsfilter.io/a/ef55703cb4d3295b0d15ca6101387ae7&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABG&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;$ABG: Issued Press Release on February 05, 18:26:00: Asbury Automotive Group Announces Pricing Of Its Private Offering Of Senior Notes Due https://s.flashalert.me/l92TH&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABG&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;$ABG: Asbury Automotive Group Announces Pricing Of Its Private Offering Of Senior Notes Due 2028 And Senior Notes ... https://www.chartmill.com/news/ABG/prnews-2020-2-5-asbury-automotive-group-announces-pricing-of-its-private-offering-of-senior-notes-due-2028-and-senior-notes-due-2030?utm_source=stocktwits&amp;amp;utm_medium=pressRelease&amp;amp;utm_content=ABG&amp;amp;utm_campaign=social_tracking&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABG&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;$ABG Asbury Automotive Group Announces Pricing Of Its Private Offering Of Senior Notes Due 2028 And Senior Notes Due 2030 \\n\\nhttps://newsfilter.io/a/400da2b9f9d1b113f980346903bcb4ef&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABG&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;Asbury Automotive Group&amp;#39;s PT cut by SunTrust Banks, Inc. to . hold rating. https://www.marketbeat.com/r/1341215 $ABG&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABG&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;BULLISH NEWS FOR $ABG\\n\\nhttps://finance.yahoo.com/news/know-asbury-automotive-abg-rating-170005382.html&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABG&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:{&quot;basic&quot;:&quot;Bullish&quot;}}},{&quot;body&quot;:&quot;A review of $ABG ’s past year earnings was reported yesterday.The earnings reported by a firm often differ from its cash flows. This distinction, referred to as &amp;quot;accruals&amp;quot;, speaks to the firm’s estimation of profits not yet received. see http://www.financial-education-hub.com/1/ABG.However, managers may make mistakes intentionally or unintentionally in the estimation, making the realization of accruals inconsistent with cash flows.Based on this, whereas two firms report the same earnings, the one with higher accruals would perform worse next period.&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABG&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;A new $ABG report about financial statements and exhibits and other topics just got released by #SEC. Read it now https://wallmine.com/filing/redirect/12101180?utm_source=stocktwits&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABG&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;Asbury (ABG) announces earnings. $2.53 EPS. Beats estimates. 45.37M earnings. $ABG https://www.tipranks.com/stocks/ABG/earnings-calendar?ref=TREarnings&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABG&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;$ABG Craig-Hallum Downgrades to Hold : PT $110.00 https://stockhoot.com/ExtSymbol.aspx?from=AnalystRatingTweet&amp;amp;symbol=ABG&amp;amp;t=66&amp;amp;Social=StockTwits&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABG&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;Asbury Automotive Group downgraded by Craig Hallum to hold. https://www.marketbeat.com/r/1341017 $ABG&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABG&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}},{&quot;body&quot;:&quot;What do you think of this? $ABG RSI Indicator left the oversold zone. View odds of uptrend. https://tickeron.com/go/1204531&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABG&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:{&quot;basic&quot;:&quot;Bullish&quot;}}},{&quot;body&quot;:&quot;Asbury Automotive Group announces earnings. $2.53 EPS. Beats estimates. $1.89b revenue.  https://www.marketbeat.com/s/441917 $ABG&quot;,&quot;symbols&quot;:[{&quot;symbol&quot;:&quot;ABG&quot;}],&quot;entities&quot;:{&quot;sentiment&quot;:null}}]</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('[{\"body\":\"$AAPL had approximately 2395M USD go to the short side at 52 pct short  Bears and Bulls are fighting close  https://www.algowins.com/?wdt_c ... (7899 characters truncated) ... d in looking for some emoji overkill\",\"symbols\":[{\"symbol\":\"AAPL\"},{\"symbol\":\"SPY\"},{\"symbol\":\"ITOT\"}],\"entities\":{\"sentiment\":{\"basic\":\"Bullish\"}}}]',),\n",
       " ('[{\"body\":\"$ABEO wow not that much activity here.. usually means rocket lovers are selling 👍\",\"symbols\":[{\"symbol\":\"ABEO\"}],\"entities\":{\"sentiment\":{\" ... (4622 characters truncated) ... \":[{\"symbol\":\"ABEO\"}],\"entities\":{\"sentiment\":{\"basic\":\"Bullish\"}}},{\"body\":\"$ABEO 😬👇🏼\",\"symbols\":[{\"symbol\":\"ABEO\"}],\"entities\":{\"sentiment\":null}}]',),\n",
       " ('[{\"body\":\"$ABG reported 9 new insider trades to the SEC in the last 2 minutes.\\\\n\\\\n2,222 shares acquired by Stax William Frederick (CAO &amp; Interi ... (8325 characters truncated) ... . $2.53 EPS. Beats estimates. $1.89b revenue.  https://www.marketbeat.com/s/441917 $ABG\",\"symbols\":[{\"symbol\":\"ABG\"}],\"entities\":{\"sentiment\":null}}]',)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "select * from twits limit 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データ変換のためのテーブルを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * hive://admin@master.ykono.work:10000\n",
      "Done.\n",
      " * hive://admin@master.ykono.work:10000\n",
      "Done.\n",
      " * hive://admin@master.ykono.work:10000\n",
      "Done.\n",
      " * hive://admin@master.ykono.work:10000\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql create table message_extracted (symbols array<struct<symbol:string>>, sentiment STRING, body STRING) STORED AS TEXTFILE\n",
    "%sql create table message_filtered (symbols array<struct<symbol:string>>, sentiment STRING, body STRING) STORED AS TEXTFILE\n",
    "%sql create table message_exploded (symbol string, sentiment STRING, body STRING) STORED AS TEXTFILE\n",
    "%sql create table sentiment_data (sentiment int, body STRING) STORED AS TEXTFILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "元のデータから必要なデータのみを抽出します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * hive://admin@master.ykono.work:10000\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "insert overwrite table message_extracted \n",
    "select message.symbols, message.entities.sentiment, message.body from twits \n",
    "lateral view explode(messages) messages as message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * hive://admin@master.ykono.work:10000\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>symbols</th>\n",
       "        <th>sentiment</th>\n",
       "        <th>body</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>[{&quot;symbol&quot;:&quot;AAPL&quot;}]</td>\n",
       "        <td>None</td>\n",
       "        <td>$AAPL had approximately 2395M USD go to the short side at 52 pct short  Bears and Bulls are fighting close  https://www.algowins.com/?wdt_column_filter[1]=AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>[{&quot;symbol&quot;:&quot;AAPL&quot;}]</td>\n",
       "        <td>Bullish</td>\n",
       "        <td>$AAPL nice squeeze on the daily. If jobs report goes well 330 tomorrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>[{&quot;symbol&quot;:&quot;AAPL&quot;}]</td>\n",
       "        <td>None</td>\n",
       "        <td>In the last month $AAPL has a been trading in the 302.22 - 327.85 range, which is quite wide. https://www.chartmill.com/stock/quote/AAPL/technical-analysis?key=bb853040-a4ac-41c6-b549-d218d2f21b32&amp;amp;utm_source=stocktwits&amp;amp;utm_medium=TA&amp;amp;utm_content=AAPL&amp;amp;utm_campaign=social_tracking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>[{&quot;symbol&quot;:&quot;AAPL&quot;},{&quot;symbol&quot;:&quot;EROS&quot;}]</td>\n",
       "        <td>Bullish</td>\n",
       "        <td>$EROS SEEING IS BELIEVING - EROSNOW IS NOW ON APPLE TV+ AS OF TODAY! </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>[{&quot;symbol&quot;:&quot; &quot;}]</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('[{\"symbol\":\"AAPL\"}]', None, '$AAPL had approximately 2395M USD go to the short side at 52 pct short  Bears and Bulls are fighting close  https://www.algowins.com/?wdt_column_filter[1]=AAPL'),\n",
       " ('[{\"symbol\":\"AAPL\"}]', 'Bullish', '$AAPL nice squeeze on the daily. If jobs report goes well 330 tomorrow'),\n",
       " ('[{\"symbol\":\"AAPL\"}]', None, 'In the last month $AAPL has a been trading in the 302.22 - 327.85 range, which is quite wide. https://www.chartmill.com/stock/quote/AAPL/technical-analysis?key=bb853040-a4ac-41c6-b549-d218d2f21b32&amp;utm_source=stocktwits&amp;utm_medium=TA&amp;utm_content=AAPL&amp;utm_campaign=social_tracking'),\n",
       " ('[{\"symbol\":\"AAPL\"},{\"symbol\":\"EROS\"}]', 'Bullish', '$EROS SEEING IS BELIEVING - EROSNOW IS NOW ON APPLE TV+ AS OF TODAY! '),\n",
       " ('[{\"symbol\":\" \"}]', None, None)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "select * from message_extracted limit 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * hive://admin@master.ykono.work:10000\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>_c0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>9036</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(9036,)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "select count(*) from message_extracted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データから、メッセージ・ボディが含まれているデータのみを取り出します。同時に、銘柄に対するセンチメントを文字列からを数値に置換します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * hive://admin@master.ykono.work:10000\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "insert overwrite table message_filtered \n",
    "select symbols, \n",
    "    case sentiment when 'Bearish' then -2 when 'Bullish' then 2 ELSE 0 END as sentiment, \n",
    "    body from message_extracted \n",
    "    where body is not null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * hive://admin@master.ykono.work:10000\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>symbols</th>\n",
       "        <th>sentiment</th>\n",
       "        <th>body</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>[{&quot;symbol&quot;:&quot;AAPL&quot;}]</td>\n",
       "        <td>0</td>\n",
       "        <td>$AAPL had approximately 2395M USD go to the short side at 52 pct short  Bears and Bulls are fighting close  https://www.algowins.com/?wdt_column_filter[1]=AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>[{&quot;symbol&quot;:&quot;AAPL&quot;}]</td>\n",
       "        <td>2</td>\n",
       "        <td>$AAPL nice squeeze on the daily. If jobs report goes well 330 tomorrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>[{&quot;symbol&quot;:&quot;AAPL&quot;}]</td>\n",
       "        <td>0</td>\n",
       "        <td>In the last month $AAPL has a been trading in the 302.22 - 327.85 range, which is quite wide. https://www.chartmill.com/stock/quote/AAPL/technical-analysis?key=bb853040-a4ac-41c6-b549-d218d2f21b32&amp;amp;utm_source=stocktwits&amp;amp;utm_medium=TA&amp;amp;utm_content=AAPL&amp;amp;utm_campaign=social_tracking</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('[{\"symbol\":\"AAPL\"}]', '0', '$AAPL had approximately 2395M USD go to the short side at 52 pct short  Bears and Bulls are fighting close  https://www.algowins.com/?wdt_column_filter[1]=AAPL'),\n",
       " ('[{\"symbol\":\"AAPL\"}]', '2', '$AAPL nice squeeze on the daily. If jobs report goes well 330 tomorrow'),\n",
       " ('[{\"symbol\":\"AAPL\"}]', '0', 'In the last month $AAPL has a been trading in the 302.22 - 327.85 range, which is quite wide. https://www.chartmill.com/stock/quote/AAPL/technical-analysis?key=bb853040-a4ac-41c6-b549-d218d2f21b32&amp;utm_source=stocktwits&amp;utm_medium=TA&amp;utm_content=AAPL&amp;utm_campaign=social_tracking')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "select * from message_filtered limit 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一つのメッセージに複数の銘柄が紐づけられています。データ正規化のため、データ１行につき、一つの銘柄を持つようにデータを変換します（同じメッセージを持つ行が複数作られます）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * hive://admin@master.ykono.work:10000\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "insert overwrite table message_exploded \n",
    "select symbol.symbol, sentiment, body from message_filtered lateral view explode(symbols) symbols as symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * hive://admin@master.ykono.work:10000\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>symbol</th>\n",
       "        <th>sentiment</th>\n",
       "        <th>body</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>AAPL</td>\n",
       "        <td>0</td>\n",
       "        <td>$AAPL had approximately 2395M USD go to the short side at 52 pct short  Bears and Bulls are fighting close  https://www.algowins.com/?wdt_column_filter[1]=AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>AAPL</td>\n",
       "        <td>2</td>\n",
       "        <td>$AAPL nice squeeze on the daily. If jobs report goes well 330 tomorrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>AAPL</td>\n",
       "        <td>0</td>\n",
       "        <td>In the last month $AAPL has a been trading in the 302.22 - 327.85 range, which is quite wide. https://www.chartmill.com/stock/quote/AAPL/technical-analysis?key=bb853040-a4ac-41c6-b549-d218d2f21b32&amp;amp;utm_source=stocktwits&amp;amp;utm_medium=TA&amp;amp;utm_content=AAPL&amp;amp;utm_campaign=social_tracking</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('AAPL', '0', '$AAPL had approximately 2395M USD go to the short side at 52 pct short  Bears and Bulls are fighting close  https://www.algowins.com/?wdt_column_filter[1]=AAPL'),\n",
       " ('AAPL', '2', '$AAPL nice squeeze on the daily. If jobs report goes well 330 tomorrow'),\n",
       " ('AAPL', '0', 'In the last month $AAPL has a been trading in the 302.22 - 327.85 range, which is quite wide. https://www.chartmill.com/stock/quote/AAPL/technical-analysis?key=bb853040-a4ac-41c6-b549-d218d2f21b32&amp;utm_source=stocktwits&amp;utm_medium=TA&amp;utm_content=AAPL&amp;utm_campaign=social_tracking')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "select * from message_exploded limit 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここまでの操作で、元の複雑な構造のデータから、１レコードにつき、銘柄、センチメント、メッセージ本文を持つフォーマットに変換されました。\n",
    "銘柄毎のセンチメントの件数などの分析を行うには、このテーブルを利用します。\n",
    "\n",
    "この後の感情分析では、メッセージ本文の文字列から、センチメントを判定する予測モデルを構築します。そのため銘柄情報は利用しないため、センチメントとメッセージ本文のみを取り出します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * hive://admin@master.ykono.work:10000\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "insert overwrite table sentiment_data \n",
    "select sentiment, body from message_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * hive://admin@master.ykono.work:10000\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>sentiment</th>\n",
       "        <th>body</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>0</td>\n",
       "        <td>$AAPL had approximately 2395M USD go to the short side at 52 pct short  Bears and Bulls are fighting close  https://www.algowins.com/?wdt_column_filter[1]=AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2</td>\n",
       "        <td>$AAPL nice squeeze on the daily. If jobs report goes well 330 tomorrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>0</td>\n",
       "        <td>In the last month $AAPL has a been trading in the 302.22 - 327.85 range, which is quite wide. https://www.chartmill.com/stock/quote/AAPL/technical-analysis?key=bb853040-a4ac-41c6-b549-d218d2f21b32&amp;amp;utm_source=stocktwits&amp;amp;utm_medium=TA&amp;amp;utm_content=AAPL&amp;amp;utm_campaign=social_tracking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2</td>\n",
       "        <td>$EROS SEEING IS BELIEVING - EROSNOW IS NOW ON APPLE TV+ AS OF TODAY! </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>0</td>\n",
       "        <td>How I Plan To Trade Tesla Stock https://youtu.be/RLXL4V6J6RE $TSLA 📈 </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2</td>\n",
       "        <td>$GOOG $GOOGL $MSFT $AAPL $AMZN   </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>0</td>\n",
       "        <td>$AAPL Does anyone know what date you need to own shares by in order to get the dividend?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2</td>\n",
       "        <td>$AAPL </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2</td>\n",
       "        <td>$AAPL $400 by August... seems about right! Undervalued at these levels and at the $400 price target!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>0</td>\n",
       "        <td>$AAPL </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(0, '$AAPL had approximately 2395M USD go to the short side at 52 pct short  Bears and Bulls are fighting close  https://www.algowins.com/?wdt_column_filter[1]=AAPL'),\n",
       " (2, '$AAPL nice squeeze on the daily. If jobs report goes well 330 tomorrow'),\n",
       " (0, 'In the last month $AAPL has a been trading in the 302.22 - 327.85 range, which is quite wide. https://www.chartmill.com/stock/quote/AAPL/technical-analysis?key=bb853040-a4ac-41c6-b549-d218d2f21b32&amp;utm_source=stocktwits&amp;utm_medium=TA&amp;utm_content=AAPL&amp;utm_campaign=social_tracking'),\n",
       " (2, '$EROS SEEING IS BELIEVING - EROSNOW IS NOW ON APPLE TV+ AS OF TODAY! '),\n",
       " (0, 'How I Plan To Trade Tesla Stock https://youtu.be/RLXL4V6J6RE $TSLA 📈 '),\n",
       " (2, '$GOOG $GOOGL $MSFT $AAPL $AMZN   '),\n",
       " (0, '$AAPL Does anyone know what date you need to own shares by in order to get the dividend?'),\n",
       " (2, '$AAPL '),\n",
       " (2, '$AAPL $400 by August... seems about right! Undervalued at these levels and at the $400 price target!'),\n",
       " (0, '$AAPL ')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "select * from sentiment_data limit 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSONファイルの作成\n",
    "\n",
    "加工したデータをJSONファイルとして出力します。\n",
    "\n",
    "感情分析を担当するデータサイエンティスト・機械学習エンジニアは、このJSONファイルを使います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * hive://admin@master.ykono.work:10000\n",
      "Done.\n",
      " * hive://admin@master.ykono.work:10000\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql DROP TABLE IF EXISTS json_message\n",
    "%sql create table json_message (message STRING) STORED AS TEXTFILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * hive://admin@master.ykono.work:10000\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "insert overwrite table json_message\n",
    "select to_json(named_struct('message_body', body, 'sentiment', sentiment)) from sentiment_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * hive://admin@master.ykono.work:10000\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>{&quot;message_body&quot;:&quot;$AAPL had approximately 2395M USD go to the short side at 52 pct short  Bears and Bulls are fighting close  https://www.algowins.com/?wdt_column_filter[1]=AAPL&quot;,&quot;sentiment&quot;:0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>{&quot;message_body&quot;:&quot;$AAPL nice squeeze on the daily. If jobs report goes well 330 tomorrow&quot;,&quot;sentiment&quot;:2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>{&quot;message_body&quot;:&quot;In the last month $AAPL has a been trading in the 302.22 - 327.85 range, which is quite wide. https://www.chartmill.com/stock/quote/AAPL/technical-analysis?key=bb853040-a4ac-41c6-b549-d218d2f21b32&amp;amp;utm_source=stocktwits&amp;amp;utm_medium=TA&amp;amp;utm_content=AAPL&amp;amp;utm_campaign=social_tracking&quot;,&quot;sentiment&quot;:0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>{&quot;message_body&quot;:&quot;$EROS SEEING IS BELIEVING - EROSNOW IS NOW ON APPLE TV+ AS OF TODAY! &quot;,&quot;sentiment&quot;:2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>{&quot;message_body&quot;:&quot;How I Plan To Trade Tesla Stock https://youtu.be/RLXL4V6J6RE $TSLA 📈 &quot;,&quot;sentiment&quot;:0}</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('{\"message_body\":\"$AAPL had approximately 2395M USD go to the short side at 52 pct short  Bears and Bulls are fighting close  https://www.algowins.com/?wdt_column_filter[1]=AAPL\",\"sentiment\":0}',),\n",
       " ('{\"message_body\":\"$AAPL nice squeeze on the daily. If jobs report goes well 330 tomorrow\",\"sentiment\":2}',),\n",
       " ('{\"message_body\":\"In the last month $AAPL has a been trading in the 302.22 - 327.85 range, which is quite wide. https://www.chartmill.com/stock/quote/ ... (29 characters truncated) ... b853040-a4ac-41c6-b549-d218d2f21b32&amp;utm_source=stocktwits&amp;utm_medium=TA&amp;utm_content=AAPL&amp;utm_campaign=social_tracking\",\"sentiment\":0}',),\n",
       " ('{\"message_body\":\"$EROS SEEING IS BELIEVING - EROSNOW IS NOW ON APPLE TV+ AS OF TODAY! \",\"sentiment\":2}',),\n",
       " ('{\"message_body\":\"How I Plan To Trade Tesla Stock https://youtu.be/RLXL4V6J6RE $TSLA 📈 \",\"sentiment\":0}',)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "select * from json_message limit 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`HQL_SELECT_MESSAGE`をあなたが作成したデータベースを指定してください**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from __future__ import print_function\n",
    "\n",
    "HQL_SELECT_MESSAGE = \"select * from admin.json_message\"\n",
    "\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"JsonGen\")\\\n",
    "    .getOrCreate()\n",
    "    \n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "json_list = spark.sql(HQL_SELECT_MESSAGE)\n",
    "\n",
    "path = \"./output.json\"\n",
    "\n",
    "with open(path, mode='w') as f:\n",
    "    f.write('{\"data\":[')\n",
    "    bool_first_line = True\n",
    "    for row in json_list.rdd.collect():\n",
    "        if bool_first_line:\n",
    "            bool_first_line = False\n",
    "            f.write(row.message)\n",
    "        else:\n",
    "            # あまりスマートではありませんが、ある程度の量のデータを使ったDeep Learning処理をシミュレーションするため、\n",
    "            # 同じ情報を使って、データを嵩増ししています。\n",
    "            # API利用の制約や、演習時間の制約がなければ、\n",
    "            # 上記のWebスクレイピングで、大量の訓練データを取得することが可能です。\n",
    "            for i in range(100): \n",
    "                f.write(\",\\n\")\n",
    "                f.write(row.message)\n",
    "    \n",
    "    f.write(\"]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 cdsw cdsw 96174003 Feb  7 05:39 output.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l | grep output.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"data\":[{\"message_body\":\"$AAPL had approximately 2395M USD go to the short side at 52 pct short  Bears and Bulls are fighting close  https://www.algowins.com/?wdt_column_filter[1]=AAPL\",\"sentiment\":0},\n",
      "{\"message_body\":\"$AAPL nice squeeze on the daily. If jobs report goes well 330 tomorrow\",\"sentiment\":2},\n",
      "{\"message_body\":\"$AAPL nice squeeze on the daily. If jobs report goes well 330 tomorrow\",\"sentiment\":2},\n",
      "{\"message_body\":\"$AAPL nice squeeze on the daily. If jobs report goes well 330 tomorrow\",\"sentiment\":2},\n",
      "{\"message_body\":\"$AAPL nice squeeze on the daily. If jobs report goes well 330 tomorrow\",\"sentiment\":2},\n",
      "{\"message_body\":\"$AAPL nice squeeze on the daily. If jobs report goes well 330 tomorrow\",\"sentiment\":2},\n",
      "{\"message_body\":\"$AAPL nice squeeze on the daily. If jobs report goes well 330 tomorrow\",\"sentiment\":2},\n",
      "{\"message_body\":\"$AAPL nice squeeze on the daily. If jobs report goes well 330 tomorrow\",\"sentiment\":2},\n",
      "{\"message_body\":\"$AAPL nice squeeze on the daily. If jobs report goes well 330 tomorrow\",\"sentiment\":2},\n",
      "{\"message_body\":\"$AAPL nice squeeze on the daily. If jobs report goes well 330 tomorrow\",\"sentiment\":2},\n",
      "{\"message_body\":\"$YUMA watching. On the verge of a breakout.\",\"sentiment\":2},\n",
      "{\"message_body\":\"$YUMA watching. On the verge of a breakout.\",\"sentiment\":2},\n",
      "{\"message_body\":\"$YUMA watching. On the verge of a breakout.\",\"sentiment\":2},\n",
      "{\"message_body\":\"$YUMA watching. On the verge of a breakout.\",\"sentiment\":2},\n",
      "{\"message_body\":\"$YUMA watching. On the verge of a breakout.\",\"sentiment\":2},\n",
      "{\"message_body\":\"$YUMA watching. On the verge of a breakout.\",\"sentiment\":2},\n",
      "{\"message_body\":\"$YUMA watching. On the verge of a breakout.\",\"sentiment\":2},\n",
      "{\"message_body\":\"$YUMA watching. On the verge of a breakout.\",\"sentiment\":2},\n",
      "{\"message_body\":\"$YUMA watching. On the verge of a breakout.\",\"sentiment\":2},\n",
      "{\"message_body\":\"$YUMA watching. On the verge of a breakout.\",\"sentiment\":2}]}"
     ]
    }
   ],
   "source": [
    "!head output.json\n",
    "!tail output.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 感情分析\n",
    "\n",
    "投資判断のために、企業の価値を考慮する際のアプローチとして、従来の枠組みにとらわれない様々な情報（オルタナティブ・データ）を用いることを考えます。\n",
    "\n",
    "投資家の判断を左右し得る様々な情報を入力とし、投資判断のための定量的なシグナルに変換する予測モデルを構築します。\n",
    "入力となるデータには様々なものがあります。以下はその例です。\n",
    "\n",
    "- ニュース（製品のリコール、自然災害など）\n",
    "\n",
    "ニューラルネットワークを使ったDeep Learningによって、入力データの形式を問わず、予測モデルを構築することができます。\n",
    "\n",
    "ここでは、ソーシャルメディアサイトStockTwitsの投稿を使用します。\n",
    "StockTwitsのコミュニティは、投資家、トレーダー、起業家により利用されています。\n",
    "\n",
    "感情のスコアを生成するこれらのtwitを中心にモデルを構築します。\n",
    "\n",
    "モデルの訓練のためには、入力に対応するラベルが必要になります。ラベルの精度は、モデルの訓練に当たって大変重要な要素です。\n",
    "\n",
    "センチメントの度合いを把握するために、非常にネガティブ、ネガティブ、ニュートラル、ポジティブ、非常にポジティブという5段階のスケールを使用します。それぞれ、-2から2までの数値に対応しています。\n",
    "\n",
    "このラベル付きデータによって訓練されたモデルを使用して、自然言語を入力として、その文章の背後にある感情を予測するモデルを構築します。\n",
    "\n",
    "\n",
    "### データの確認\n",
    "データがどのように見えるかを確認します。\n",
    "\n",
    "各フィールドの意味:\n",
    "\n",
    "* `'message_body'`: メッセージ本文テキスト\n",
    "* `'sentiment'`: センチメントスコア。-2から2までの５段階。0は中立。\n",
    "\n",
    "下記のような内容になっているはずです。\n",
    "```\n",
    "{'data':\n",
    "  {'message_body': '............................',\n",
    "   'sentiment': 2},\n",
    "  {'message_body': '............................',\n",
    "   'sentiment': -2},\n",
    "   ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データを読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'message_body': '$AAPL had approximately 2395M USD go to the short side at 52 pct short  Bears and Bulls are fighting close  https://www.algowins.com/?wdt_column_filter[1]=AAPL', 'sentiment': 0}, {'message_body': '$AAPL nice squeeze on the daily. If jobs report goes well 330 tomorrow', 'sentiment': 2}, {'message_body': '$AAPL nice squeeze on the daily. If jobs report goes well 330 tomorrow', 'sentiment': 2}, {'message_body': '$AAPL nice squeeze on the daily. If jobs report goes well 330 tomorrow', 'sentiment': 2}, {'message_body': '$AAPL nice squeeze on the daily. If jobs report goes well 330 tomorrow', 'sentiment': 2}, {'message_body': '$AAPL nice squeeze on the daily. If jobs report goes well 330 tomorrow', 'sentiment': 2}, {'message_body': '$AAPL nice squeeze on the daily. If jobs report goes well 330 tomorrow', 'sentiment': 2}, {'message_body': '$AAPL nice squeeze on the daily. If jobs report goes well 330 tomorrow', 'sentiment': 2}, {'message_body': '$AAPL nice squeeze on the daily. If jobs report goes well 330 tomorrow', 'sentiment': 2}, {'message_body': '$AAPL nice squeeze on the daily. If jobs report goes well 330 tomorrow', 'sentiment': 2}]\n"
     ]
    }
   ],
   "source": [
    "with open('./output.json', 'r') as f:\n",
    "    twits = json.load(f)\n",
    "\n",
    "print(twits['data'][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データ件数の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "593901\n"
     ]
    }
   ],
   "source": [
    "print(len(twits['data']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データの前処理\n",
    "\n",
    "テキストを前処理します。\n",
    "\n",
    "本文に含まれるティッカーシンボル（「$シンボル」で示される）はセンチメントに関する情報を提供しないため削除します。\n",
    "また、「@ユーザー名」で、ユーザに関する情報が記載されていますが、これもまたセンチメント情報を提供しないため、削除します。\n",
    "URLも削除します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### メッセージ本文とセンチメント・ラベルのリスト化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [twit['message_body'] for twit in twits['data']]\n",
    "# Since the sentiment scores are discrete, we'll scale the sentiments to 0 to 4 for use in our network\n",
    "sentiments = [twit['sentiment'] + 2 for twit in twits['data']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### プリプロセス関数の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/cdsw/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "\n",
    "def preprocess(message):\n",
    "    \"\"\"\n",
    "    入力として文字列を受け取り、次の操作を実行する: \n",
    "        - 全てのアルファベットを小文字に変換\n",
    "        - URLを削除\n",
    "        - ティッカーシンボルを削除 \n",
    "        - 句読点を削除\n",
    "        - 文字列をスペースで分割しトークン化する\n",
    "        - シングル・キャラクターのトークンを削除\n",
    "    \n",
    "    パラメータ\n",
    "    ----------\n",
    "        message : 前処理の対象テキストメッセージ\n",
    "        \n",
    "    戻り値\n",
    "    -------\n",
    "        tokens: 前処理後のトークン配列\n",
    "    \"\"\" \n",
    "    #TODO: Implement \n",
    "    \n",
    "    # Lowercase the twit message\n",
    "    text = message.lower()\n",
    "    \n",
    "    # Replace URLs with a space in the message\n",
    "    text = re.sub(\"http(s)?://([\\w\\-]+\\.)+[\\w-]+(/[\\w\\- ./?%&=]*)?\",' ', text)\n",
    "    \n",
    "    # Replace ticker symbols with a space. The ticker symbols are any stock symbol that starts with $.\n",
    "    text = re.sub(\"\\$[^ \\t\\n\\r\\f]+\", ' ', text)\n",
    "    \n",
    "    # Replace StockTwits usernames with a space. The usernames are any word that starts with @.\n",
    "    text = re.sub(\"@[^ \\t\\n\\r\\f]+\", ' ', text)\n",
    "\n",
    "    # Replace everything not a letter with a space\n",
    "    text = re.sub(\"[^a-z]\", ' ', text)\n",
    "    \n",
    "    \n",
    "    # Tokenize by splitting the string on whitespace into a list of words\n",
    "    tokens = text.split()\n",
    "\n",
    "    # Lemmatize words using the WordNetLemmatizer. You can ignore any word that is not longer than one character.\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    tokens = [wnl.lemmatize(w, pos='v') for w in tokens if len(w) > 1]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitsメッセージ前処理\n",
    "上記で定義した`preprocess`関数を全てStockTwitメッセージ・データに適用します。\n",
    "\n",
    "※この処理には、データのサイズに応じて多少時間がかかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['have', 'approximately', 'usd', 'go', 'to', 'the', 'short', 'side', 'at', 'pct', 'short', 'bear', 'and', 'bull', 'be', 'fight', 'close', 'aapl'], ['nice', 'squeeze', 'on', 'the', 'daily', 'if', 'job', 'report', 'go', 'well', 'tomorrow'], ['nice', 'squeeze', 'on', 'the', 'daily', 'if', 'job', 'report', 'go', 'well', 'tomorrow']]\n",
      "593901\n"
     ]
    }
   ],
   "source": [
    "tokenized = list(map(preprocess, messages))\n",
    "\n",
    "print(tokenized[:3])\n",
    "print(len(tokenized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words\n",
    "\n",
    "すべてのメッセージがトークン化されたので、ボキャブラリ（語彙）データを作成します。\n",
    "その際に、コーパス全体で各単語が出現する頻度をカウントします\n",
    "（[`Counter`](https://docs.python.org/3.1/library/collections.html#collections.Counter)関数を利用）。\n",
    "\n",
    "※この処理には、データのサイズに応じて多少時間がかかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['have', 'approximately', 'usd', 'go', 'to', 'the', 'short', 'side', 'at', 'pct', 'short', 'bear', 'and']\n",
      "7600018\n",
      "593901\n",
      "[[16, 115, 111, 35, 2, 0, 19, 98, 23, 116, 19, 101, 7, 144, 3, 240, 86, 2310], [216, 485, 9, 0, 159, 120, 751, 12, 35, 227, 188], [216, 485, 9, 0, 159, 120, 751, 12, 35, 227, 188]]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "#words = []\n",
    "#for tokens in tokenized:\n",
    "#    for token in tokens:\n",
    "#        words.append(token)\n",
    "out_list = tokenized\n",
    "words = [element for in_list in out_list for element in in_list]\n",
    "\n",
    "print(words[:13])\n",
    "print(len(words))\n",
    "\n",
    "\"\"\"\n",
    "Create a vocabulary by using Bag of words\n",
    "\"\"\"\n",
    "\n",
    "word_counts = Counter(words)\n",
    "sorted_vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "int_to_vocab = {ii: word for ii, word in enumerate(sorted_vocab)}\n",
    "vocab_to_int = {word:ii for ii, word in int_to_vocab.items()}\n",
    "\n",
    "bow = []\n",
    "for tokens in tokenized:\n",
    "    bow.append([vocab_to_int[token] for token in tokens])\n",
    "\n",
    "print(len(bow))\n",
    "print(bow[:3])\n",
    "\n",
    "# This BOW will not be used because it is not filtered to eliminate common words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 単語の重要性（メッセージに現れる頻度）に応じた調整\n",
    "\n",
    "ボキャブラリーを使用して、「the」、「and」、「it」などの最も一般的な単語の一部を削除します。\n",
    "これらの単語は非常に一般的であるため、センチメントを特定する目的に寄与せず、ニューラルネットワークへの入力のノイズとなります。これらを除外することで、ネットワークの学習時間を短縮することができます。\n",
    "\n",
    "また、非常に稀にしか用いられない単語も削除します。\n",
    "ここでは、各単語のカウントをメッセージの数で除算する必要があります。\n",
    "\n",
    "次に、メッセージのごく一部にしか表示されない単語を削除します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(sorted_vocab): 5664\n",
      "sorted_vocab - top: ['the', 'of', 'to']\n",
      "sorted_vocab - least: ['php', 'ref', 'nqjktv', 'png', 'developments', 'sayin', 'geologist', 'specialization', 'fossil', 'deposit', 'convince', 'merit', 'laughable', 'terrify', 'verge']\n",
      "freqs[the]: 0.02588164922767288\n",
      "high_cutoff: 20\n",
      "low_cutoff: 2e-06\n",
      "K_most_common: ['the', 'of', 'to', 'be', 'amp', 'utm', 'file', 'and', 'in', 'on', 'form', 'for', 'report', 'share', 'sec', 'medium', 'have', 'by', 'campaign', 'short']\n",
      "len(filtered_words): 5644\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Set the following variables:\n",
    "    freqs\n",
    "    low_cutoff\n",
    "    high_cutoff\n",
    "    K_most_common\n",
    "\"\"\"\n",
    "\n",
    "print(\"len(sorted_vocab):\",len(sorted_vocab))\n",
    "print(\"sorted_vocab - top:\", sorted_vocab[:3])\n",
    "print(\"sorted_vocab - least:\", sorted_vocab[-15:])\n",
    "\n",
    "# Dictionart that contains the Frequency of words appearing in messages.\n",
    "# The key is the token and the value is the frequency of that word in the corpus.\n",
    "total_count = len(words)\n",
    "freqs = {word: count/total_count for word, count in word_counts.items()}\n",
    "\n",
    "#print(\"freqs[supplication]:\",freqs[\"supplication\"] )\n",
    "print(\"freqs[the]:\",freqs[\"the\"] )\n",
    "\n",
    "\"\"\"\n",
    "This was the post by Ricardo:\n",
    "\n",
    "there's no exact value for low_cutoff and high_cutoff, \n",
    "however I'd recommend you to use \n",
    "a low_cutoff that's around 0.000002 and 0.000007 \n",
    "(This depends on the values you get from your freqs calculations) and \n",
    "a high_cutofffrom 5 to 20 (this depends on the most_common values from the bow).\n",
    "\"\"\"\n",
    "\n",
    "# Float that is the frequency cutoff. Drop words with a frequency that is lower or equal to this number.\n",
    "low_cutoff = 0.000002\n",
    "\n",
    "# Integer that is the cut off for most common words. Drop words that are the `high_cutoff` most common words.\n",
    "\"\"\"\n",
    "example_count = []\n",
    "example_count.append(sorted_vocab.index(\"the\"))\n",
    "example_count.append(sorted_vocab.index(\"for\"))\n",
    "example_count.append(sorted_vocab.index(\"of\"))\n",
    "print(example_count)\n",
    "high_cutoff = min(example_count)\n",
    "\"\"\"\n",
    "high_cutoff = 20\n",
    "print(\"high_cutoff:\",high_cutoff)\n",
    "print(\"low_cutoff:\",low_cutoff)\n",
    "\n",
    "# The k most common words in the corpus. Use `high_cutoff` as the k.\n",
    "#K_most_common = [word for word in sorted_vocab[:high_cutoff]]\n",
    "K_most_common = sorted_vocab[:high_cutoff]\n",
    "\n",
    "print(\"K_most_common:\",K_most_common)\n",
    "\n",
    "\n",
    "filtered_words = [word for word in freqs if (freqs[word] > low_cutoff and word not in K_most_common)]\n",
    "\n",
    "print(\"len(filtered_words):\",len(filtered_words)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### フィルターされた単語を削除して語彙を更新\n",
    "ボキャブラリーに役立つ3つの変数を作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(tokenized): 593901\n",
      "len(filtered): 593901\n",
      "tokenized[:1] [['have', 'approximately', 'usd', 'go', 'to', 'the', 'short', 'side', 'at', 'pct', 'short', 'bear', 'and', 'bull', 'be', 'fight', 'close', 'aapl']]\n",
      "filtered[:1] [['approximately', 'usd', 'go', 'side', 'at', 'pct', 'bear', 'bull', 'fight', 'close', 'aapl']]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Set the following variables:\n",
    "    vocab\n",
    "    id2vocab\n",
    "    filtered\n",
    "\"\"\"\n",
    "\n",
    "# A dictionary for the `filtered_words`. The key is the word and value is an id that represents the word. \n",
    "vocab =  {word:ii for ii, word in enumerate(filtered_words)}\n",
    "# Reverse of the `vocab` dictionary. The key is word id and value is the word. \n",
    "id2vocab = {ii:word for word, ii in vocab.items()}\n",
    "# tokenized with the words not in `filtered_words` removed.\n",
    "\n",
    "print(\"len(tokenized):\", len(tokenized))\n",
    "\n",
    "filtered = [[token for token in tokens if token in vocab] for tokens in tokenized]\n",
    "print(\"len(filtered):\", len(filtered))\n",
    "print(\"tokenized[:1]\", tokenized[:1])\n",
    "print(\"filtered[:1]\",filtered[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分類クラス間のバランス\n",
    "\n",
    "訓練データのラベルには、一般に偏りがあることがよく見受けられます（例外的なデータは少ない）。\n",
    "例えば、データの50％がニュートラルであること場合、毎回0（ニュートラル）を予測するだけで、ネットワークの精度が50％になることを意味します。\n",
    "\n",
    "ネットワークが適切に学習できるように、クラスのバランスを取る必要があります。つまり、それぞれのセンチメントスコアがデータにほぼ同じ頻度で表含まれていることが望ましいと言えます。\n",
    "\n",
    "ここでは、中立的な感情を持つデータを全体の20%になるように、ランダムにドロップします。\n",
    "\n",
    "データに含まれるニュートラルデータのパーセンテージと、データ削除により期待されるパーセンテージの値を使って、\n",
    "データをドロップする確率を求めます。\n",
    "\n",
    "同時に、長さが0のメッセージを削除します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep prob: 0.0504957488448718\n"
     ]
    }
   ],
   "source": [
    "balanced = {'messages': [], 'sentiments':[]}\n",
    "\n",
    "n_neutral = sum(1 for each in sentiments if each == 2)\n",
    "N_examples = len(sentiments)\n",
    "\n",
    "keep_prob = (N_examples - n_neutral)/4/n_neutral\n",
    "\n",
    "print(\"keep prob:\", keep_prob)\n",
    "\n",
    "for idx, sentiment in enumerate(sentiments):\n",
    "    message = filtered[idx]\n",
    "    if len(message) == 0:\n",
    "        # skip this message because it has length zero\n",
    "        continue\n",
    "    elif sentiment != 2 or random.random() < keep_prob:\n",
    "        balanced['messages'].append(message)\n",
    "        balanced['sentiments'].append(sentiment) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "バランスされたデータ中、センチメントが「ニュートラル」であるデータの割合を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21339761481857397"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_neutral = sum(1 for each in balanced['sentiments'] if each == 2)\n",
    "N_examples = len(balanced['sentiments'])\n",
    "n_neutral/N_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let's convert our tokens into integer ids which we can pass to the network.\n",
    "\n",
    "メッセージをID（数値）に変換します。この処理は、ニューラルネットワークの入力として用いるために必要です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = [[vocab[word] for word in message] for message in balanced['messages']]\n",
    "sentiments = balanced['sentiments']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ボキャブラリ・ファイルを保存します。このファイルは、予測の際に、入力を変換するために必要になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('vocab.pickle', 'wb') as f:\n",
    "    pickle.dump(vocab, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ニューラルネットワーク\n",
    "これでボキャブラリーができたので、トークンをIDに変換し、それをネットワークに渡すことができます。ネットワークを定義します\n",
    "\n",
    "下記は、ネットワークの概要です：\n",
    "\n",
    "#### Embed -> RNN -> Dense -> Softmax\n",
    "\n",
    "### SentimentClassifier (感情分類器)実装\n",
    "\n",
    "クラスは、3つの主要な部分で構成されています：: \n",
    "\n",
    "1. init function `__init__` \n",
    "2. forward pass `forward`  \n",
    "3. hidden state `init_hidden`. \n",
    "\n",
    "出力層では、softmaxを使用します。出力フォーマットによって出力層を選択します。\n",
    "\n",
    "（例えば、出力が２値/バイナリであれば、シグモイド関数）\n",
    "\n",
    "このネットワークでは、センチメントスコアには5つのクラスがあるためsoftmaxが適しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, lstm_size, output_size, lstm_layers=1, dropout=0.1):\n",
    "        \"\"\"\n",
    "        Initialize the model by setting up the layers.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "            vocab_size : The vocabulary size.\n",
    "            embed_size : The embedding layer size.\n",
    "            lstm_size : The LSTM layer size.\n",
    "            output_size : The output size.\n",
    "            lstm_layers : The number of LSTM layers.\n",
    "            dropout : The dropout probability.\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = embed_size\n",
    "        self.lstm_size = lstm_size\n",
    "        self.output_size = output_size\n",
    "        self.lstm_layers = lstm_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embed_size)\n",
    "        self.lstm = nn.LSTM(self.embed_size, self.lstm_size, self.lstm_layers, dropout=self.dropout)\n",
    "        \n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(lstm_size, output_size)\n",
    "        \n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        \"\"\" \n",
    "        Initializes hidden state\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "            batch_size : The size of batches.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "            hidden_state\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # 隠れ層として、n_layers x batch_size x hidden_dimの構造を持つテンソルを二つ作成し、ゼロで初期化\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        \n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        hidden = (weight.new(self.lstm_layers, batch_size,self.lstm_size).zero_(),\n",
    "                         weight.new(self.lstm_layers, batch_size, self.lstm_size).zero_())\n",
    "        return hidden\n",
    "\n",
    "\n",
    "    def forward(self, nn_input, hidden_state):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on nn_input.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "            nn_input : The batch of input to the NN.\n",
    "            hidden_state : The LSTM hidden state.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            logps: log softmax output\n",
    "            hidden_state: The new hidden state.\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        batch_size = nn_input.size(0)\n",
    "        \n",
    "        # embed\n",
    "        embeds = self.embedding(nn_input)\n",
    "        \n",
    "        # LSTM\n",
    "        lstm_out, hidden_state = self.lstm(embeds, hidden_state)\n",
    "        \n",
    "        \"\"\"\n",
    "        remember here you do not have batch_first=True, \n",
    "        so accordingly shape your input. \n",
    "        Moreover, since now input is seq_length x batch you just need to transform lstm_out = lstm_out[-1,:,:].\n",
    "        you don't have to use batch_first=True in this case, \n",
    "        nor reshape the outputs with .view just transform your lstm_out as advised and you should be good to go.\n",
    "        \"\"\"\n",
    "        #lstm_out = lstm_out.contiguous().view(-1, self.lstm_size)    \n",
    "        lstm_out = lstm_out[-1,:,:]\n",
    "        \n",
    "        # dropout\n",
    "        out = self.dropout(lstm_out)\n",
    "        \n",
    "        # Dense Layer (nn.Linear) RNNの隠れ層から値を予測\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        # Softmax関数\n",
    "        logps = self.softmax(out)\n",
    "        \n",
    "        \n",
    "        return logps, hidden_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.4577, -1.7675, -1.4326, -1.6824, -1.7611],\n",
      "        [-1.4568, -1.7760, -1.4235, -1.6869, -1.7618],\n",
      "        [-1.4543, -1.7657, -1.4373, -1.6784, -1.7653],\n",
      "        [-1.4654, -1.7506, -1.4481, -1.6645, -1.7659]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = SentimentClassifier(len(vocab), 10, 6, 5, dropout=0.1, lstm_layers=2)\n",
    "model.embedding.weight.data.uniform_(-1, 1)\n",
    "input = torch.randint(0, 1000, (5, 4), dtype=torch.int64)\n",
    "batch_size = 4\n",
    "hidden = model.init_hidden(4)\n",
    "\n",
    "logps, _ = model.forward(input, hidden)\n",
    "print(logps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### トレーニング\n",
    "### DataLoaderとバッチ処理\n",
    "ここで、データをループするために使用できるジェネレーターを構築します。\n",
    "\n",
    "効率化のため、シーケンスをバッチとして渡します。\n",
    "\n",
    "入力テンソルは次のような形になります：(sequence_length, batch_size)\n",
    "\n",
    "したがって、シーケンスが40トークンで、25シーケンスを渡す場合、入力サイズは(40, 25)になります。\n",
    "\n",
    "シーケンスの長さを40に設定した場合、40トークンより多いまたは少ないメッセージは、以下のように処理します。\n",
    "- 40トークン未満のメッセージの場合、空のスポットにゼロを埋め込む。\n",
    "   - データを処理する前にRNNが何も開始しないように、必ずパッドを残しておく必要がある。\n",
    "   - メッセージに20個のトークンがある場合、最初の20個のスポットは0になる。\n",
    "- メッセージに40個を超えるトークンがある場合、最初の40個のトークンを保持。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def dataloader(messages, labels, sequence_length=30, batch_size=32, shuffle=False):\n",
    "def dataloader(messages, labels, sequence_length=20, batch_size=32, shuffle=False):\n",
    "    \"\"\" \n",
    "    Build a dataloader.\n",
    "    \"\"\"\n",
    "    if shuffle:\n",
    "        indices = list(range(len(messages)))\n",
    "        random.shuffle(indices)\n",
    "        messages = [messages[idx] for idx in indices]\n",
    "        labels = [labels[idx] for idx in indices]\n",
    "\n",
    "    total_sequences = len(messages)\n",
    "\n",
    "    for ii in range(0, total_sequences, batch_size):\n",
    "        batch_messages = messages[ii: ii+batch_size]\n",
    "        \n",
    "        # First initialize a tensor of all zeros\n",
    "        batch = torch.zeros((sequence_length, len(batch_messages)), dtype=torch.int64)\n",
    "        for batch_num, tokens in enumerate(batch_messages):\n",
    "            token_tensor = torch.tensor(tokens)\n",
    "            # Left pad!\n",
    "            start_idx = max(sequence_length - len(token_tensor), 0)\n",
    "            batch[start_idx:, batch_num] = token_tensor[:sequence_length]\n",
    "        \n",
    "        label_tensor = torch.tensor(labels[ii: ii+len(batch_messages)])\n",
    "        \n",
    "        yield batch, label_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  データの分割（訓練用と検証用）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Split data into training and validation datasets. Use an appropriate split size.\n",
    "The features are the `token_ids` and the labels are the `sentiments`.\n",
    "\"\"\"   \n",
    "\n",
    "split_frac = 0.98 # for small data\n",
    "#split_frac = 0.8 # for big data\n",
    "\n",
    "## split data into training, validation, and test data (features and labels, x and y)\n",
    "\n",
    "split_idx = int(len(token_ids)*split_frac)\n",
    "train_features, remaining_features = token_ids[:split_idx], token_ids[split_idx:]\n",
    "train_labels, remaining_labels = sentiments[:split_idx], sentiments[split_idx:]\n",
    "\n",
    "test_idx = int(len(remaining_features)*0.5)\n",
    "valid_features, test_features = remaining_features[:test_idx], remaining_features[test_idx:]\n",
    "valid_labels, test_labels = remaining_labels[:test_idx], remaining_labels[test_idx:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### トレーニング準備\n",
    "\n",
    "利用可能なデバイス(CUDA/GPUまたはGPU)を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentClassifier(\n",
       "  (embedding): Embedding(5645, 1024)\n",
       "  (lstm): LSTM(1024, 512, num_layers=2, dropout=0.2)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=512, out_features=5, bias=True)\n",
       "  (softmax): LogSoftmax()\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = SentimentClassifier(len(vocab)+1, 200, 128, 5, dropout=0.)\n",
    "model = SentimentClassifier(len(vocab)+1, 1024, 512, 5, lstm_layers=2, dropout=0.2)\n",
    "model.embedding.weight.data.uniform_(-1, 1)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### トレーニング実施\n",
    "\n",
    "トレーニングを実行します。モデルの訓練の進行度合を確認するために、定期的にLossを出力します。\n",
    "\n",
    "※この処理には、データのサイズに応じて、十分な時間が必要です。\n",
    "\n",
    "GPUを備えた環境で実行する場合、ターミナルで以下のコマンドを実行することで、GPUが利用されていることを確認することができます（ GPU実行中、コマンド実行により表示されるテーブルの右上のVolatile GPU-Utilのパーセンテージ値が増えます）\n",
    "```\n",
    "$ watch nvidia-smi\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "Epoch: 1/5... Step: 100... Loss: 0.040382... Total Loss: 0.219460\n",
      "Epoch: 1/5... Step: 200... Loss: 0.000827... Total Loss: 0.118474\n",
      "Starting epoch 2\n",
      "Epoch: 2/5... Step: 100... Loss: 0.002647... Total Loss: 0.076874\n",
      "Epoch: 2/5... Step: 200... Loss: 0.001187... Total Loss: 0.059721\n",
      "Starting epoch 3\n",
      "Epoch: 3/5... Step: 100... Loss: 0.000218... Total Loss: 0.047139\n",
      "Epoch: 3/5... Step: 200... Loss: 0.000292... Total Loss: 0.040001\n",
      "Starting epoch 4\n",
      "Epoch: 4/5... Step: 100... Loss: 0.000775... Total Loss: 0.034031\n",
      "Epoch: 4/5... Step: 200... Loss: 0.000757... Total Loss: 0.030247\n",
      "Starting epoch 5\n",
      "Epoch: 5/5... Step: 100... Loss: 0.000326... Total Loss: 0.026750\n",
      "Epoch: 5/5... Step: 200... Loss: 0.001380... Total Loss: 0.024398\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "epochs = 5\n",
    "batch_size =  64\n",
    "batch_size =  512\n",
    "learning_rate = 0.001\n",
    "\n",
    "print_every = 100\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "model.train()\n",
    "\n",
    "#val_losses = []\n",
    "total_losses = []\n",
    "#accuracy = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('Starting epoch {}'.format(epoch + 1))\n",
    "    \n",
    "    steps = 0\n",
    "    for text_batch, labels in dataloader(\n",
    "            train_features, train_labels, batch_size=batch_size, sequence_length=20, shuffle=True):\n",
    "        steps += 1\n",
    "        hidden = model.init_hidden(labels.shape[0]) \n",
    "        \n",
    "        # デバイス(CPU, GPU)の設定\n",
    "        text_batch, labels = text_batch.to(device), labels.to(device)\n",
    "        for each in hidden:\n",
    "            each.to(device)\n",
    "        \n",
    "        # モデルのトレーニング\n",
    "        hidden = tuple([each.data for each in hidden])\n",
    "        model.zero_grad()\n",
    "        output, hidden = model(text_batch, hidden)\n",
    "        loss = criterion(output.squeeze(), labels)\n",
    "        loss.backward()\n",
    "        clip = 5\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate loss\n",
    "        #val_losses.append(loss.item())\n",
    "        total_losses.append(loss.item())\n",
    "        \n",
    "        correct_count = 0.0\n",
    "        if steps % print_every == 0:\n",
    "            model.eval()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            ps = torch.exp(output)\n",
    "            top_p, top_class = ps.topk(1, dim=1)\n",
    "            #?top_class = top_class.to(device)\n",
    "            #?labels = labels.to(device)\n",
    "\n",
    "            correct_count += torch.sum(top_class.squeeze()== labels)\n",
    "            #accuracy.append(100*correct_count/len(labels))\n",
    "            \n",
    "            # Print metrics\n",
    "            print(\"Epoch: {}/{}...\".format(epoch+1, epochs),\n",
    "                 \"Step: {}...\".format(steps),\n",
    "                 \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                 \"Total Loss: {:.6f}\".format(np.mean(total_losses)),\n",
    "                 #\"Collect Count: {}\".format(correct_count),\n",
    "                 #\"Accuracy: {:.2f}\".format((100*correct_count/len(labels))),\n",
    "                 # AttributeError: 'torch.dtype' object has no attribute 'type'\n",
    "                 #\"Accuracy Avg: {:.2f}\".format(np.mean(accuracy))\n",
    "                 )\n",
    "            \n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'state_dict': model.state_dict()}, 'checkpoint.pth.tar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 予測（Prediction）関数の作成\n",
    "\n",
    "訓練されたモデルを使って、入力されたテキストから予測結果を生成するpredict関数を実装します。\n",
    "\n",
    "テキストは、ネットワークに渡される前に前処理される必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cdsw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/cdsw/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "cur_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "print(cur_dir)\n",
    "sys.path.append(cur_dir)\n",
    "\n",
    "vocab_filename = 'vocab.pickle'\n",
    "vocab_path = cur_dir + \"/\" + vocab_filename\n",
    "vocab_l = pickle.load(open(vocab_path, 'rb'))\n",
    "\n",
    "#model_path = cur_dir + \"/\" + \"model.torch\"\n",
    "#model_l = torch.load(model_path, map_location='cpu')\n",
    "\n",
    "model_l = SentimentClassifier(len(vocab_l)+1, 1024, 512, 5, lstm_layers=2, dropout=0.2)\n",
    "checkpoint = torch.load('./checkpoint.pth.tar')\n",
    "model_l.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "class UnknownWordsError(Exception):\n",
    "  \"Only unknown words are included in text\"\n",
    "\n",
    "\n",
    "def predict_func(text, model, vocab):\n",
    "    \"\"\" \n",
    "    Make a prediction on a single sentence.\n",
    "    Parameters\n",
    "    ----------\n",
    "        text : The string to make a prediction on.\n",
    "        model : The model to use for making the prediction.\n",
    "        vocab : Dictionary for word to word ids. The key is the word and the value is the word id.\n",
    "    Returns\n",
    "    -------\n",
    "        pred : 予測値（numpyベクトル）\n",
    "    \"\"\"\n",
    "\n",
    "    tokens = preprocess(text)    \n",
    "\n",
    "    # Filter non-vocab words\n",
    "    tokens = [token for token in tokens if token in vocab] #pass\n",
    "    # Convert words to ids\n",
    "    tokens = [vocab[token] for token in tokens] #pass\n",
    "\n",
    "    if len(tokens) == 0:\n",
    "        raise UnknownWordsError\n",
    "\n",
    "    # Adding a batch dimension\n",
    "    text_input = torch.from_numpy(np.asarray(torch.LongTensor(tokens).view(-1, 1)))\n",
    "\n",
    "    # Get the NN output       \n",
    "    batch_size = 1\n",
    "    hidden = model.init_hidden(batch_size) #pass\n",
    "    \n",
    "    logps, _ = model(text_input, hidden) #pass\n",
    "    # Take the exponent of the NN output to get a range of 0 to 1 for each label.\n",
    "    pred = torch.round(logps.squeeze())#pass\n",
    "    pred = torch.exp(logps) \n",
    "    \n",
    "    return pred\n",
    "\n",
    "\n",
    "def predict_api(args):\n",
    "    \"\"\" \n",
    "    Make a prediction on a single sentence.\n",
    "    Parameters\n",
    "    ----------\n",
    "        args : 入力（Pythonディクショナリ）\n",
    "    Returns\n",
    "    -------\n",
    "        pred : 予測値（Python配列）\n",
    "    \"\"\"\n",
    "    text = args.get('text')\n",
    "    try:\n",
    "        result = predict_func(text, model_l, vocab_l)\n",
    "        return result.detach().numpy()[0]\n",
    "    except UnknownWordsError:\n",
    "        return [0,0,1,0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ポジティブなセンチメントを連想させる文章を入力として予測（適宜、文章を変更して実行してみることができます）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.02395445  0.02243885  0.03738181  0.02565586  0.89056903]\n"
     ]
    }
   ],
   "source": [
    "args = {\"text\": \"I'm bullish on $goog\"}\n",
    "result = predict_api(args)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ネガティブなセンチメントを連想させる文章を入力として予測（適宜、文章を変更して実行してみることができます）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.76727909  0.07537365  0.05268526  0.08244011  0.02222182]\n"
     ]
    }
   ],
   "source": [
    "args = {\"text\": \"I'm bearish on $goog\"}\n",
    "result = predict_api(args)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ボキャブラリ辞書に存在しない単語のみの文章を入力として予測（適宜、文章を変更して実行してみることができます）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "args = {\"text\": \"kono yoshiyuki\"}\n",
    "result = predict_api(args)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最後に\n",
    "\n",
    "データベースを削除する場合は、**データベース名を適切に変更した後で**下記を実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * hive://admin@master.ykono.work:10000\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql DROP DATABASE IF EXISTS admin CASCADE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
